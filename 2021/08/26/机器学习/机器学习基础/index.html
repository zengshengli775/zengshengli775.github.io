<!-- build time:Fri Feb 18 2022 14:09:27 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><meta name="referrer" content="no-referrer"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Sakura" href="https://zengshengli775.gitee.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Sakura" href="https://zengshengli775.gitee.io/atom.xml"><link rel="alternate" type="application/json" title="Sakura" href="https://zengshengli775.gitee.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="机器学习"><link rel="canonical" href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><title>机器学习基础 - 机器学习 | Sakura = Sakura = 我以为18岁之后是19岁，19岁之后是18岁，20岁永远都不会到来 。</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">机器学习基础</h1><div class="meta"><span class="item" title="创建时间：2021-08-26 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-08-26T00:00:00+08:00">2021-08-26</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>26k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>24 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Sakura</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="http://www.dmoe.cc/random.php?335969"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?577241"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?650550"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?247733"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?958775"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?927891"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="lzs"><meta itemprop="description" content="我以为18岁之后是19岁，19岁之后是18岁，20岁永远都不会到来 。, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Sakura"></span><div class="body md" itemprop="articleBody"><h3 id="李宏毅机器学习笔记"><a class="anchor" href="#李宏毅机器学习笔记">#</a> <span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlbWwtbm90ZXMvIy8=">李宏毅机器学习笔记</span></h3><h3 id="黑马程序员3天快速入门python机器学习"><a class="anchor" href="#黑马程序员3天快速入门python机器学习">#</a> <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMW50NDExcjd0ag==">黑马程序员 3 天快速入门 python 机器学习</span></h3><h3 id="黑马-3天快速入门-python机器学习-html"><a class="anchor" href="#黑马-3天快速入门-python机器学习-html">#</a> <span class="exturl" data-url="aHR0cHM6Ly9lbWFpbG5jdWVkdWNuLW15LnNoYXJlcG9pbnQuY29tLzpmOi9nL3BlcnNvbmFsLzYxMDgxMTkwOTRfZW1haWxfbmN1X2VkdV9jbi9Fc0tseHBxRmhYSkRtNElVMFJiYld6MEJ6WFFqb2ZvZUNKOTZXTEpKQThmUm1BP2U9bjFTaDV1">[黑马] 3 天快速入门 python 机器学习 - html</span></h3><h2 id="1机器学习概述"><a class="anchor" href="#1机器学习概述">#</a> 1. 机器学习概述</h2><h3 id="11什么是机器学习"><a class="anchor" href="#11什么是机器学习">#</a> 1.1 什么是机器学习</h3><p>机器学习是从<strong>数据</strong>中<strong>自动分析获得模型</strong>，并利用<strong>模型</strong>对未知数据进行预测。</p><p>数据集构成：特征值 + 目标值</p><h3 id="12机器学习算法分类"><a class="anchor" href="#12机器学习算法分类">#</a> 1.2 机器学习算法分类</h3><ul><li>监督学习 (supervised learning)（预测）<ul><li>定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值 (称为回归），或是输出是有限个离散值（称作分类）。</li><li><strong>分类 k - 近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络</strong></li><li><strong>回归 线性回归、岭回归</strong></li></ul></li><li>无监督学习 (unsupervised learning)<ul><li>定义：输入数据是由输入特征值所组成。</li><li><strong>聚类 k-means</strong></li></ul></li></ul><h3 id="13开发流程"><a class="anchor" href="#13开发流程">#</a> 1.3 开发流程</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532152.jpg" alt="开发流程.png"></p><h2 id="2特征工程"><a class="anchor" href="#2特征工程">#</a> 2. 特征工程</h2><h3 id="21数据集"><a class="anchor" href="#21数据集">#</a> 2.1 数据集</h3><h4 id="211-可用数据集"><a class="anchor" href="#211-可用数据集">#</a> 2.1.1 可用数据集</h4><p>​ Kaggle 网址：<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cw==">https://www.kaggle.com/datasets</span></p><p>​ UCI 数据集网址： <span class="exturl" data-url="aHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwv">http://archive.ics.uci.edu/ml/</span></p><p>​ scikit-learn 网址：<span class="exturl" data-url="aHR0cDovL3NjaWtpdC1sZWFybi5vcmcvc3RhYmxlL2RhdGFzZXRzL2luZGV4Lmh0bWw=">http://scikit-learn.org/stable/datasets/index.html#datasets</span></p><h4 id="212-sklearn"><a class="anchor" href="#212-sklearn">#</a> 2.1.2 sklearn</h4><ul><li>sklearn.datasets 加载获取流行数据集<ul><li>datasets.load_*()	获取小规模数据集，数据包含在 datasets 里</li><li>datasets.fetch_*(data_home=None)	获取大规模数据集，需要从网络上下载，函数的第一个参数是 data_home，表示数据集下载的目录，默认是～/scikit_learn_data/</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 获取鸢尾花数据集</span></pre></td></tr><tr><td data-num="3"></td><td><pre>iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花数据集的返回值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 返回值是一个继承自字典的 Bench</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的特征值:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的目标值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花特征的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花目标值的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的描述：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>DESCR<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="22-特征工程介绍"><a class="anchor" href="#22-特征工程介绍">#</a> 2.2 特征工程介绍</h3><p>​	特征工程是使用<strong>专业背景知识和技巧处理数据</strong>，<strong>使得特征能在机器学习算法上发挥更好的作用的过程</strong>。</p><p><strong>特征工程包含内容</strong></p><ul><li>特征抽取</li><li>特征预处理</li><li>特征降维</li></ul><h3 id="23-特征抽取"><a class="anchor" href="#23-特征抽取">#</a> 2.3 特征抽取</h3><p>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</p><ul><li>字典特征提取 (特征离散化)</li><li>文本特征提取</li><li>图像特征提取（深度学习将介绍）</li></ul><h4 id="232-字典特征提取"><a class="anchor" href="#232-字典特征提取">#</a> 2.3.2 字典特征提取</h4><p><strong>作用：对字典数据进行特征值化</strong></p><p><strong>对于特征当中存在类别信息的我们都会做 one-hot 编码处理</strong></p><ul><li>sklearn.feature_extraction.DictVectorizer(sparse=True,…)<ul><li>DictVectorizer.fit_transform (X) X: 字典或者包含字典的迭代器返回值：返回 sparse 矩阵</li><li>DictVectorizer.inverse_transform (X) X:array 数组或者 sparse 矩阵 返回值：转换之前数据格式</li><li>DictVectorizer.get_feature_names () 返回类别名称</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">dict_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对字典类型的数据进行特征抽取</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment">#sparse=False 参数，one-hot 编码处理</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回的结果:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment"># 打印特征名字</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="233-文本特征提取"><a class="anchor" href="#233-文本特征提取">#</a> 2.3.3 文本特征提取</h4><p><strong>作用：对文本数据进行特征值化</strong></p><h5 id="2331sklearnfeature_extractiontextcountvectorizerstop_words返回词频矩阵统计每个样本特征词出现的个数"><a class="anchor" href="#2331sklearnfeature_extractiontextcountvectorizerstop_words返回词频矩阵统计每个样本特征词出现的个数">#</a> 2.3.3.1.<strong>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</strong>	<strong>返回词频矩阵，统计每个样本特征词出现的个数</strong>。</h5><ul><li><p>CountVectorizer.fit_transform (X) X: 文本或者包含文本字符串的可迭代对象 返回值：返回 sparse 矩阵</p></li><li><p>CountVectorizer.inverse_transform (X) X:array 数组或者 sparse 矩阵 返回值：转换之前数据格</p></li><li><p>CountVectorizer.get_feature_names () 返回值：单词列表</p><h6 id="23311对英文进行特征提取"><a class="anchor" href="#23311对英文进行特征提取">#</a> 2.3.3.1.1<strong> 对英文进行特征提取</strong></h6></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对文本进行特征抽取，countvetorizer</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"life is short,i like like python"</span><span class="token punctuation">,</span> <span class="token string">"life is too long,i dislike python"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment">#调用 fit_transform 方法输入数据并转换 （注意返回格式，</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h6 id="23312对中文进行特征提取"><a class="anchor" href="#23312对中文进行特征提取">#</a> 2.3.3.1.2<strong> 对中文进行特征提取</strong></h6><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    对中文进行分词</pre></td></tr><tr><td data-num="7"></td><td><pre>    "我爱北京天安门"————>"我 爱 北京 天安门"</pre></td></tr><tr><td data-num="8"></td><td><pre>    :param text:</pre></td></tr><tr><td data-num="9"></td><td><pre>    :return: text</pre></td></tr><tr><td data-num="10"></td><td><pre>    """</pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 用结巴对中文字符串进行分词</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    text <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">return</span> text</pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_chinese_count_demo2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    对中文进行特征抽取</pre></td></tr><tr><td data-num="19"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="20"></td><td><pre>    """</pre></td></tr><tr><td data-num="21"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            <span class="token string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            <span class="token string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment"># 将原始数据转换成分好词的形式</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h5 id="2332sklearnfeature_extractiontexttfidfvectorizer用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度"><a class="anchor" href="#2332sklearnfeature_extractiontexttfidfvectorizer用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度">#</a> 2.3.3.2.<strong>sklearn.feature_extraction.text.TfidfVectorizer</strong>	<strong>用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</strong></h5><ul><li>词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率</li><li>逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的 idf，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取以 10 为底的对数得到</strong></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532964.jpg" alt="tfidf公式.png"></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    对中文进行分词</pre></td></tr><tr><td data-num="7"></td><td><pre>    "我爱北京天安门"————>"我 爱 北京 天安门"</pre></td></tr><tr><td data-num="8"></td><td><pre>    :param text:</pre></td></tr><tr><td data-num="9"></td><td><pre>    :return: text</pre></td></tr><tr><td data-num="10"></td><td><pre>    """</pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 用结巴对中文字符串进行分词</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    text <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">return</span> text</pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_chinese_tfidf_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    对中文进行特征抽取</pre></td></tr><tr><td data-num="19"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="20"></td><td><pre>    """</pre></td></tr><tr><td data-num="21"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            <span class="token string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            <span class="token string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment"># 将原始数据转换成分好词的形式</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="24-特征预处理"><a class="anchor" href="#24-特征预处理">#</a> 2.4 特征预处理</h3><p>通过<strong>一些转换函数</strong>将特征数据<strong>转换成更加适合算法模型</strong>的特征数据过程</p><ul><li>数值型数据的无量纲化：<ul><li>归一化</li><li>标准化</li></ul></li></ul><h4 id="241归一化"><a class="anchor" href="#241归一化">#</a> 2.4.1 归一化</h4><p>通过对原始数据进行变换把数据映射到 (默认为 [0,1]) 之间</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532546.jpg" alt="image.png"></p><blockquote><p>作用于每一列，max 为一列的最大值，min 为一列的最小值，那么 X’’为最终结果，mx，mi 分别为指定区间值默认 mx 为 1,mi 为 0</p></blockquote><ul><li>sklearn.preprocessing.MinMaxScaler (feature_range=(0,1)… )<ul><li>MinMaxScalar.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li></ul></li><li>返回值：转换后的形状相同的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">minmax_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    归一化演示</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    transfer <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'milage'</span><span class="token punctuation">,</span><span class="token string">'Liters'</span><span class="token punctuation">,</span><span class="token string">'Consumtime'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最小值最大值归一化处理的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p><strong>归一化鲁棒性较差，只适合传统精确小数据场景。</strong></p><h4 id="242标准化"><a class="anchor" href="#242标准化">#</a> 2.4.2 标准化</h4><p>通过对原始数据进行变换把数据变换到均值为 0, 标准差为 1 范围内</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533098.jpg" alt="image.png"></p><p>作用于每一列，mean 为平均值，σ 为标准差</p><ul><li>sklearn.preprocessing.StandardScaler( )<ul><li>处理之后每列来说所有数据都聚集在均值 0 附近标准差差为 1</li><li>StandardScaler.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li></ul></li><li>返回值：转换后的形状相同的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">stand_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    标准化演示</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'milage'</span><span class="token punctuation">,</span><span class="token string">'Liters'</span><span class="token punctuation">,</span><span class="token string">'Consumtime'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"标准化的结果:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每一列特征的平均值：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>mean_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每一列特征的方差：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>var_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p>在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。</p><h3 id="25-特征降维"><a class="anchor" href="#25-特征降维">#</a> 2.5 特征降维</h3><h4 id="251-降维"><a class="anchor" href="#251-降维">#</a> 2.5.1 降维</h4><p><strong>降维</strong>是指在某些限定条件下，<strong>降低随机变量 (特征) 个数</strong>，得到<strong>一组 “不相关” 主变量</strong>的过程</p><ul><li><strong>特征选择</strong></li><li><strong>主成分分析</strong></li></ul><h4 id="252特征选择"><a class="anchor" href="#252特征选择">#</a> 2.5.2 特征选择</h4><p>数据中包含<strong>冗余或无关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出主要特征</strong>。</p><h5 id="2521方法"><a class="anchor" href="#2521方法">#</a> 2.5.2.1 方法</h5><ul><li>Filter (过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联<ul><li><strong>方差选择法：低方差特征过滤</strong></li><li><strong>相关系数</strong></li></ul></li><li>Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul><li><strong>决策树：信息熵、信息增益</strong></li><li><strong>正则化：L1、L2</strong></li><li><strong>深度学习：卷积等</strong></li></ul></li></ul><h5 id="2522过滤式"><a class="anchor" href="#2522过滤式">#</a> 2.5.2.2 过滤式</h5><ul><li><p>特征方差小：某个特征大多样本的值比较相近</p></li><li><p>特征方差大：某个特征很多样本的值都有差别</p></li><li><p>sklearn.feature_selection.VarianceThreshold(threshold = 0.0)</p><ul><li>删除所有低方差特征</li><li>Variance.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li><li>返回值：训练集差异低于 threshold 的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。</li></ul></li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">variance_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    删除低方差特征——特征选择</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"factor_returns.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    transfer <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"删除低方差特征的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"形状：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="253相关系数"><a class="anchor" href="#253相关系数">#</a> 2.5.3 相关系数</h4><p><strong>相关系数的值介于–1 与 + 1 之间，即–1≤ r ≤+1</strong>。其性质如下：</p><ul><li><strong>当 r&gt;0 时，表示两变量正相关，r&lt;0 时，两变量为负相关</strong></li><li>当 | r|=1 时，表示两变量为完全相关，当 r=0 时，表示两变量间无相关关系</li><li><strong>当 0&lt;|r|&lt;1 时，表示两变量存在一定程度的相关。且 | r | 越接近 1，两变量间线性关系越密切；|r | 越接近于 0，表示两变量的线性相关越弱</strong></li><li><strong>一般可按三级划分：|r|&lt;0.4 为低度相关；0.4≤|r|&lt;0.7 为显著性相关；0.7≤|r|&lt;1 为高度线性相关</strong></li></ul><blockquote><p>这个符号：|r | 为 r 的绝对值， |-5| = 5</p></blockquote><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533904.jpg" alt="image.png"></p><ul><li>from scipy.stats import pearsonr<ul><li>x : (N,) array_like</li><li>y : (N,) array_like Returns: (Pearson’s correlation coefficient, p-value)</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">pearsonr_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    相关系数计算</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"factor_returns.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    factor <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'pe_ratio'</span><span class="token punctuation">,</span> <span class="token string">'pb_ratio'</span><span class="token punctuation">,</span> <span class="token string">'market_cap'</span><span class="token punctuation">,</span> <span class="token string">'return_on_asset_net_profit'</span><span class="token punctuation">,</span> <span class="token string">'du_return_on_equity'</span><span class="token punctuation">,</span> <span class="token string">'ev'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>              <span class="token string">'earnings_per_share'</span><span class="token punctuation">,</span> <span class="token string">'revenue'</span><span class="token punctuation">,</span> <span class="token string">'total_expense'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>factor<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>factor<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="17"></td><td><pre>                <span class="token string">"指标%s与指标%s之间的相关性大小为%f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>factor<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> factor<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span>factor<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span>factor<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="26主成分分析pca"><a class="anchor" href="#26主成分分析pca">#</a> 2.6 主成分分析 (PCA)</h3><ul><li><p>定义：<strong>高维数据转化为低维数据的过程</strong>，在此过程中<strong>可能会舍弃原有数据、创造新的变量</strong></p></li><li><p>作用：<strong>是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。</strong></p></li><li><p>应用：回归分析或者聚类分析当中</p></li><li><p>sklearn.decomposition.PCA(n_components=None)</p><ul><li>将数据分解为较低维数空间</li><li>n_components:<ul><li><strong>小数：表示保留百分之多少的信息</strong></li><li><strong>整数：减少到多少特征</strong></li></ul></li><li>PCA.fit_transform (X) X:numpy array 格式的数据 [n_samples,n_features]</li><li>返回值：转换后指定维度的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">pca_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对数据进行PCA降维</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 1、实例化 PCA, 小数 —— 保留多少信息</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    transfer <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data1 <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"保留90%的信息，降维结果为：\n"</span><span class="token punctuation">,</span> data1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token comment"># 1、实例化 PCA, 整数 —— 指定降维到的维数</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    transfer2 <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    data2 <span class="token operator">=</span> transfer2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"降维到3维的结果：\n"</span><span class="token punctuation">,</span> data2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533446.jpg" alt="image.png"></p><h2 id="3分类算法"><a class="anchor" href="#3分类算法">#</a> 3. 分类算法</h2><h3 id="31数据集介绍与划分"><a class="anchor" href="#31数据集介绍与划分">#</a> 3.1 数据集介绍与划分</h3><h4 id="数据集的划分"><a class="anchor" href="#数据集的划分">#</a> 数据集的划分</h4><p>机器学习一般的数据集会划分为两个部分：</p><ul><li>训练数据：用于训练，构建模型</li><li>测试数据：在模型检验时使用，用于评估模型是否有效</li></ul><p>划分比例：</p><ul><li>训练集：70% 80% 75%</li><li>测试集：30% 20% 30%</li></ul><h4 id="api"><a class="anchor" href="#api">#</a> API</h4><ul><li><p>sklearn.model_selection.train_test_split(</p><p>arrays, *</p><p>options)</p><ul><li>x 数据集的特征值</li><li>y 数据集的标签值</li><li>test_size 测试集的大小，一般为 float</li><li>random_state 随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。</li><li>return ，测试集特征训练集特征值值，训练标签，测试标签 (默认随机取)</li></ul></li></ul><h4 id="sklearn数据集介绍"><a class="anchor" href="#sklearn数据集介绍">#</a> sklearn 数据集介绍</h4><h4 id="api-2"><a class="anchor" href="#api-2">#</a> API</h4><ul><li>sklearn.datasets<ul><li>加载获取流行数据集</li><li>datasets.load_*()<ul><li>获取小规模数据集，数据包含在 datasets 里</li></ul></li><li>datasets.fetch_*(data_home=None)<ul><li>获取大规模数据集，需要从网络上下载，函数的第一个参数是 data_home，表示数据集下载的目录，默认是～/scikit_learn_data/</li></ul></li></ul></li></ul><h4 id="分类和回归数据集"><a class="anchor" href="#分类和回归数据集">#</a> 分类和回归数据集</h4><ul><li>分类数据集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533830.jpg" alt="image.png"></p><ul><li>sklearn.datasets.fetch_20newsgroups(data_home=None,subset=‘train’)<ul><li>subset: 'train' 或者 'test','all'，可选，选择要加载的数据集。训练集的 “训练”，测试集的 “测试”，两者的 “全部”</li></ul></li><li>回归数据集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533845.jpg" alt="image.png"></p><h4 id="返回类型"><a class="anchor" href="#返回类型">#</a> 返回类型</h4><ul><li><p>load</p><p>和 fetch</p><p>返回的数据类型 datasets.base.Bunch (字典格式)</p><ul><li>data：特征数据数组，是 [n_samples * n_features] 的二维 numpy.ndarray 数组</li><li>target：标签数组，是 n_samples 的一维 numpy.ndarray 数组</li><li>DESCR：数据描述</li><li>feature_names：特征名，新闻数据，手写数字、回归数据集没有</li><li>target_names：标签名</li></ul></li></ul><h3 id="32sklearn转换器和估计器"><a class="anchor" href="#32sklearn转换器和估计器">#</a> 3.2sklearn 转换器和估计器</h3><h4 id="1转换器"><a class="anchor" href="#1转换器">#</a> 1. 转换器</h4><p>特征工程的步骤:</p><ul><li>1、实例化 (实例化的是一个转换器类 (Transformer))</li><li>2、调用 fit_transform (对于文档建立分类词频矩阵，不能同时调用)</li></ul><p>我们把特征工程的接口称之为转换器，其中转换器调用有这么几种形式</p><ul><li>fit_transform</li><li>fit</li><li>transform</li></ul><p><strong>这几个方法之间的区别:</strong></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std1 <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std1<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2 <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">:</span> StandardScaler<span class="token punctuation">(</span>copy<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> with_mean<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> with_std<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>从中可以看出，fit_transform 的作用相当于 transform 加上 fit。但是为什么还要提供单独的 fit 呢，我们还是使用原来的 std2 来进行标准化看看</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>       <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="2估计器sklearn机器学习算法的实现"><a class="anchor" href="#2估计器sklearn机器学习算法的实现">#</a> 2. 估计器 (sklearn 机器学习算法的实现)</h4><p>在 sklearn 中，估计器 (estimator) 是一个重要的角色，是一类实现了算法的 API</p><ul><li>1、用于分类的估计器：<ul><li>sklearn.neighbors k - 近邻算法</li><li>sklearn.naive_bayes 贝叶斯</li><li>sklearn.linear_model.LogisticRegression 逻辑回归</li><li>sklearn.tree 决策树与随机森林</li></ul></li><li>2、用于回归的估计器：<ul><li>sklearn.linear_model.LinearRegression 线性回归</li><li>sklearn.linear_model.Ridge 岭回归</li></ul></li><li>3、用于无监督学习的估计器<ul><li>sklearn.cluster.KMeans 聚类</li></ul></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534346.jpg" alt="image.png"></p><h3 id="33-k-近邻算法knn"><a class="anchor" href="#33-k-近邻算法knn">#</a> 3.3 K - 近邻算法 (KNN)</h3><h4 id="定义"><a class="anchor" href="#定义">#</a> 定义</h4><p>如果一个样本在特征空间中的<strong> k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别</strong>，则该样本也属于这个类别。</p><blockquote><p>来源：KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法</p></blockquote><h4 id="距离公式"><a class="anchor" href="#距离公式">#</a> 距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534200.jpg" alt="image.png"></p><h4 id="k-近邻算法api"><a class="anchor" href="#k-近邻算法api">#</a> K - 近邻算法 API</h4><ul><li>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm='auto')<ul><li>n_neighbors：int, 可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li>algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给 fit 方法的值来决定最合适的算法。 (不同实现方式影响效率)</li></ul></li></ul><h4 id="预测签到位置"><a class="anchor" href="#预测签到位置">#</a> 预测签到位置</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534376.jpg" alt="image.png"></p><p>数据介绍：将根据用户的位置，准确性和时间戳预测用户正在查看的业务。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train<span class="token punctuation">.</span>csv，test<span class="token punctuation">.</span>csv </pre></td></tr><tr><td data-num="2"></td><td><pre>row_id：登记事件的ID</pre></td></tr><tr><td data-num="3"></td><td><pre>xy：坐标</pre></td></tr><tr><td data-num="4"></td><td><pre>准确性：定位准确性 </pre></td></tr><tr><td data-num="5"></td><td><pre>时间：时间戳</pre></td></tr><tr><td data-num="6"></td><td><pre>place_id：业务的ID，这是您预测的目标</pre></td></tr></table></figure><blockquote><p>官网：<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9uYXZvc2h0YS9ncmlkLWtubi9kYXRh">https://www.kaggle.com/navoshta/grid-knn/data</span></p></blockquote><h4 id="分析"><a class="anchor" href="#分析">#</a> 分析</h4><ul><li><p>对于数据做一些基本处理（这里所做的一些处理不一定达到很好的效果，我们只是简单尝试，有些特征我们可以根据一些特征选择的方式去做处理）</p><ul><li><p>1、缩小数据集范围 DataFrame.query ()</p></li><li><p>4、删除没用的日期数据 DataFrame.drop（可以选择保留）</p></li><li><p>5、将签到位置少于 n 个用户的删除</p><p>place_count = data.groupby('place_id').count()</p><p>tf = place_count[place_count.row_id &gt; 3].reset_index()</p><p>data = data[data['place_id'].isin(tf.place_id)]</p></li></ul></li><li><p>分割数据集</p></li><li><p>标准化处理</p></li><li><p>k - 近邻预测</p></li></ul><h4 id="代码"><a class="anchor" href="#代码">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">knncls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    K近邻算法预测入住位置类别</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 一、处理数据以及特征工程</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment"># 1、读取收，缩小数据的范围</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/FBlocation/train.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 数据逻辑筛选操作 df.query ()</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"x > 1.0 &amp; x &lt; 1.25 &amp; y > 2.5 &amp; y &lt; 2.75"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 删除 time 这一列特征</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># 删除入住次数少于三次位置</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    place_count <span class="token operator">=</span> data<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'place_id'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    tf <span class="token operator">=</span> place_count<span class="token punctuation">[</span>place_count<span class="token punctuation">.</span>row_id <span class="token operator">></span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>place_id<span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token comment"># 3、取出特征值和目标值</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment"># y = data[['place_id']]</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    x <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">,</span> <span class="token string">'row_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># 4、数据分割与特征工程？</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># （1）、数据分割</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token comment"># (2)、标准化</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    std <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token comment"># 队训练集进行标准化操作</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    x_train <span class="token operator">=</span> std<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token comment"># 进行测试集的标准化操作</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    x_test <span class="token operator">=</span> std<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token comment"># 二、算法的输入训练预测</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token comment"># K 值：算法传入参数不定的值    理论上：k = 根号 (样本数)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token comment"># K 值：后面会使用参数调优方法，去轮流试出最好的参数 [1,3,5,10,20,100,200]</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token comment"># 调用 fit ()</span></pre></td></tr><tr><td data-num="52"></td><td><pre>    knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token comment"># 预测测试数据集，得出准确率</span></pre></td></tr><tr><td data-num="55"></td><td><pre>    y_predict <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测测试集类别："</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率为："</span><span class="token punctuation">,</span> knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre></pre></td></tr><tr><td data-num="61"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="34模型选择与调优"><a class="anchor" href="#34模型选择与调优">#</a> 3.4 模型选择与调优</h3><p>交叉验证目的：<strong>为了让被评估的模型更加准确可信</strong></p><p>交叉验证：将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成 5 份，其中一份作为验证集。然后经过 5 次 (组) 的测试，每次都更换不同的验证集。即得到 5 组模型的结果，取平均值作为最终结果。又称 5 折交叉验证。</p><ul><li>训练集：训练集 + 验证集</li><li>测试集：测试集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534706.jpg" alt="image.png"></p><h4 id="超参数搜索-网格搜索grid-search"><a class="anchor" href="#超参数搜索-网格搜索grid-search">#</a> 超参数搜索 - 网格搜索 (Grid Search)</h4><p>通常情况下，<strong>有很多参数是需要手动指定的（如 k - 近邻算法中的 K 值），这种叫超参数</strong>。但是手动过程繁杂，所以需要对模型预设几种超参数组合。<strong>每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</strong></p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534438.jpg" alt="image.png"></p><h4 id="模型选择与调优"><a class="anchor" href="#模型选择与调优">#</a> 模型选择与调优</h4><ul><li>sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)<ul><li>对估计器的指定参数值进行详尽搜索</li><li>estimator：估计器对象</li><li “n_neighbors”:[1,3,5]="">param_grid：估计器参数 (dict)</li><li>cv：指定几折交叉验证</li><li></li><li>fit：输入训练数据</li><li>score：准确率</li><li>结果分析：<ul><li>best<em>score</em>: 在交叉验证中验证的最好结果_</li><li>best<em>estimator</em>：最好的参数模型</li><li>cv<em>results</em>: 每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul></li></ul></li></ul><h4 id="facebook签到位置预测k值调优"><a class="anchor" href="#facebook签到位置预测k值调优">#</a> Facebook 签到位置预测 K 值调优</h4><ul><li>使用网格搜索估计器</li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 使用网格搜索和交叉验证找到合适的参数</span></pre></td></tr><tr><td data-num="2"></td><td><pre>knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>param <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>gc <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>gc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"选择了某个模型测试集当中预测的准确率为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 训练验证集的结果</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"在交叉验证当中验证的最好结果："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gc选择了的模型K值是："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每次交叉验证的结果为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="35朴素贝叶斯算法"><a class="anchor" href="#35朴素贝叶斯算法">#</a> 3.5 朴素贝叶斯算法</h3><blockquote><p>朴素贝叶斯算法 = 朴素 + 贝叶斯</p><p>朴素：变量与变量之间相互独立</p><p>贝叶斯：贝叶斯公式</p></blockquote><h4 id="条件概率与联合概率"><a class="anchor" href="#条件概率与联合概率">#</a> 条件概率与联合概率</h4><ul><li>联合概率：包含多个条件，且所有条件同时成立的概率<ul><li>记作：P (A,B)</li><li>特性：P (A, B) = P (A) P (B)</li></ul></li><li>条件概率：就是事件 A 在另外一个事件 B 已经发生条件下的发生概率<ul><li>记作：P (A|B)</li><li>特性：P (A1,A2|B) = P (A1|B) P (A2|B)</li></ul></li></ul><blockquote><p>注意：此条件概率的成立，<strong>是由于 A1,A2 相互独立的结果</strong> (记忆)</p></blockquote><h4 id="贝叶斯公式"><a class="anchor" href="#贝叶斯公式">#</a> 贝叶斯公式</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534795.jpg" alt="image.png"></p><p><strong>那么这个公式如果应用在文章分类的场景当中，我们可以这样看：</strong></p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534565.jpg" alt="image.png"></p><p>公式分为三个部分：</p><ul><li>P (C)：每个文档类别的概率 (某文档类别数／总文档数量)</li><li>P (W│C)：给定类别下特征（被预测文档中出现的词）的概率<ul><li>计算方法：P (F1│C)=Ni/N （训练文档中去计算）<ul><li>Ni 为该 F1 词在 C 类别所有文档中出现的次数</li><li>N 为所属类别 C 下的文档所有词出现的次数和</li></ul></li></ul></li><li>P (F1,F2,…) 预测文档中每个词的概率</li></ul><h4 id="拉普拉斯平滑系数"><a class="anchor" href="#拉普拉斯平滑系数">#</a> 拉普拉斯平滑系数</h4><p>目的：防止计算出的分类概率为 0</p><p><img data-src="http://tva1.sinaimg.cn/large/007QGucbgy1guz1kkl1hmj60ve05c3zu02.jpg" alt="image.png"></p><h4 id="api-3"><a class="anchor" href="#api-3">#</a> API</h4><ul><li>sklearn.naive_bayes.MultinomialNB(alpha = 1.0)<ul><li>朴素贝叶斯分类</li><li>alpha：拉普拉斯平滑系数</li></ul></li></ul><h4 id="20类新闻分类"><a class="anchor" href="#20类新闻分类">#</a> 20 类新闻分类</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534818.jpg" alt="image.png"></p><h4 id="分析-2"><a class="anchor" href="#分析-2">#</a> 分析</h4><ul><li>分割数据集</li><li>tfidf 进行的特征抽取</li><li>朴素贝叶斯预测</li></ul><h4 id="代码-2"><a class="anchor" href="#代码-2">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">nbcls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    朴素贝叶斯对新闻数据集进行预测</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 获取新闻的数据，20 个类别</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    news <span class="token operator">=</span> fetch_20newsgroups<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">'all'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 进行数据集分割</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>news<span class="token punctuation">.</span>data<span class="token punctuation">,</span> news<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 对于文本数据，进行特征抽取</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    tf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token comment"># 这里打印出来的列表是：训练集当中的所有不同词的组成的一个列表</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># print(x_train.toarray())</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token comment"># 不能调用 fit_transform</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token comment"># estimator 估计器流程</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    mlb <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>    mlb<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token comment"># 进行预测</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    y_predict <span class="token operator">=</span> mlb<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测每篇文章的类别："</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"真实类别为："</span><span class="token punctuation">,</span> y_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测准确率为："</span><span class="token punctuation">,</span> mlb<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="决策树"><a class="anchor" href="#决策树">#</a> 决策树</h3><h4 id="信息熵"><a class="anchor" href="#信息熵">#</a> 信息熵</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011450474.png" alt="信息熵公式"></p><h4 id="信息增益-定义与公式"><a class="anchor" href="#信息增益-定义与公式">#</a> 信息增益 定义与公式</h4><p>特征 A 对训练数据集 D 的信息增益 g (D,A), 定义为集合 D 的信息熵 H (D) 与特征 A 给定条件下 D 的信息条件熵 H (D|A) 之差，即公式为：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011451005.png" alt="信息增益公式"></p><p>即公式为：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011452377.png" alt="信息增益公式"></p><p>公式的详细解释：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011452988.png" alt="信息增益公式详解"></p><blockquote><p>注：信息增益表示得知特征 X 的信息而息的不确定性减少的程度使得类 Y 的信息熵减少的程度</p></blockquote><h4 id="决策树的三种算法实现"><a class="anchor" href="#决策树的三种算法实现">#</a> 决策树的三种算法实现</h4><p>当然决策树的原理不止信息增益这一种，还有其他方法。但是原理都类似，我们就不去举例计算。</p><ul><li>ID3<ul><li>信息增益 最大的准则</li></ul></li><li>C4.5<ul><li>信息增益比 最大的准则</li></ul></li><li>CART<ul><li>分类树：基尼系数 最小的准则 在 sklearn 中可以选择划分的默认原则</li><li>优势：划分更加细致（从后面例子的树显示来理解）</li></ul></li></ul><h4 id="决策树api"><a class="anchor" href="#决策树api">#</a> 决策树 API</h4><ul><li>class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)<ul><li>决策树分类器</li><li>criterion: 默认是’gini’系数，也可以选择信息增益的熵’entropy’</li><li>max_depth: 树的深度大小</li><li>random_state: 随机数种子</li></ul></li><li>其中会有些超参数：max_depth: 树的深度大小<ul><li>其它超参数我们会结合随机森林讲解</li></ul></li></ul><h4 id="泰坦尼克号乘客生存预测"><a class="anchor" href="#泰坦尼克号乘客生存预测">#</a> 泰坦尼克号乘客生存预测</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">decisioncls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    决策树进行乘客生存预测</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 1、获取数据</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    titan <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 2、数据的处理</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    x <span class="token operator">=</span> titan<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    y <span class="token operator">=</span> titan<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token comment"># print(x , y)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment"># 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># 对于 x 转换成字典数据 x.to_dict (orient="records")</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment"># [&#123;"pclass": "1st", "age": 29.00, "sex": "female"&#125;, &#123;&#125;]</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token builtin">dict</span> <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    x <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">"records"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token comment"># 分割训练集合测试集</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># 进行决策树的建立和预测</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    dc <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    dc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测的准确率为："</span><span class="token punctuation">,</span> dc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="可视化决策树"><a class="anchor" href="#可视化决策树">#</a> 可视化决策树</h4><h4 id="保存树的结构到dot文件"><a class="anchor" href="#保存树的结构到dot文件">#</a> 保存树的结构到 dot 文件</h4><ul><li>1、sklearn.tree.export_graphviz () 该函数能够导出 DOT 格式<ul><li>tree.export_graphviz(estimator,out_file='tree.dot’,feature_names=[‘’,’’])</li></ul></li><li>2、工具：(能够将 dot 文件转换为 pdf、png)<ul><li>安装 graphviz</li><li>ubuntu:sudo apt-get install graphviz Mac:brew install graphviz</li></ul></li><li>3、运行命令<ul><li>然后我们运行这个命令</li><li>dot -Tpng tree.dot -o tree.png</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>export_graphviz<span class="token punctuation">(</span>dc<span class="token punctuation">,</span> out_file<span class="token operator">=</span><span class="token string">"./tree.dot"</span><span class="token punctuation">,</span> feature_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'pclass=1st'</span><span class="token punctuation">,</span> <span class="token string">'pclass=2nd'</span><span class="token punctuation">,</span> <span class="token string">'pclass=3rd'</span><span class="token punctuation">,</span> <span class="token string">'女性'</span><span class="token punctuation">,</span> <span class="token string">'男性'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="决策树总结"><a class="anchor" href="#决策树总结">#</a> 决策树总结</h4><ul><li>优点：<ul><li>简单的理解和解释，树木可视化。</li></ul></li><li>缺点：<ul><li><strong>决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。</strong></li></ul></li><li>改进：<ul><li>减枝 cart 算法 (决策树 API 当中已经实现，随机森林参数调优有相关介绍)</li><li><strong>随机森林</strong></li></ul></li></ul><h3 id="集成学习方法之随机森林"><a class="anchor" href="#集成学习方法之随机森林">#</a> 集成学习方法之随机森林</h3><h4 id="集成学习方法"><a class="anchor" href="#集成学习方法">#</a> 集成学习方法</h4><p>集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是<strong>生成多个分类器 / 模型</strong>，各自独立地学习和作出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。</strong></p><h4 id="随机森林"><a class="anchor" href="#随机森林">#</a> 随机森林</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定。</p><h4 id="随机森林原理过程"><a class="anchor" href="#随机森林原理过程">#</a> 随机森林原理过程</h4><p>学习算法根据下列算法而建造每棵树：</p><ul><li>用 N 来表示训练用例（样本）的个数，M 表示特征数目。<ul><li>1、一次随机选出一个样本，重复 N 次， （有可能出现重复的样本）</li><li>2、随机去选出 m 个特征，m &lt;&lt;M，建立决策树</li></ul></li><li>采取 bootstrap 抽样</li></ul><h4 id="api-4"><a class="anchor" href="#api-4">#</a> API</h4><ul><li><p>class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None, bootstrap=True, random_state=None, min_samples_split=2)</p><ul><li>随机森林分类器</li><li>n_estimators：integer，optional（default = 10）森林里的树木数量 120,200,300,500,800,1200</li><li>criteria：string，可选（default =“gini”）分割特征的测量方法</li><li>max_depth：integer 或 None，可选（默认 = 无）树的最大深度 5,8,15,25,30</li><li>max_features=&quot;auto”, 每个决策树的最大特征数量<ul><li>If &quot;auto&quot;, then <code>max_features=sqrt(n_features)</code> .</li><li>If &quot;sqrt&quot;, then <code>max_features=sqrt(n_features)</code> (same as &quot;auto&quot;).</li><li>If &quot;log2&quot;, then <code>max_features=log2(n_features)</code> .</li><li>If None, then <code>max_features=n_features</code> .</li></ul></li><li>bootstrap：boolean，optional（default = True）是否在构建树时使用放回抽样</li><li>min_samples_split: 节点划分最少样本数</li><li>min_samples_leaf: 叶子节点的最小样本数</li></ul></li><li><p>超参数：n_estimator, max_depth, min_samples_split,min_samples_leaf</p></li></ul><h4 id="代码-3"><a class="anchor" href="#代码-3">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 随机森林去进行预测</span></pre></td></tr><tr><td data-num="2"></td><td><pre>rf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>param <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"n_estimators"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">,</span><span class="token number">800</span><span class="token punctuation">,</span><span class="token number">1200</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"max_depth"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 超参数调优</span></pre></td></tr><tr><td data-num="7"></td><td><pre>gc <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>rf<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>gc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"随机森林预测的准确率为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011700215.png" alt="机器学习day02"></p><h2 id="回归与聚类算法"><a class="anchor" href="#回归与聚类算法">#</a> 回归与聚类算法</h2><h3 id="线性回归"><a class="anchor" href="#线性回归">#</a> 线性回归</h3><h4 id="定义与公式"><a class="anchor" href="#定义与公式">#</a> 定义与公式</h4><p>线性回归 (Linear regression) 是利用<strong>回归方程 (函数)<strong> 对一个或</strong>多个自变量 (特征值) 和因变量 (目标值) 之间</strong>关系进行建模的一种分析方式。</p><ul><li>特点：只有一个自变量的情况称为单变量回归，大于一个自变量情况的叫做多元回归</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052058772.png" alt="线性回归公式"></p><h3 id="损失函数"><a class="anchor" href="#损失函数">#</a> 损失函数</h3><p>总损失定义为：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052102076.png" alt="线性回归损失函数"></p><ul><li>y_i 为第 i 个训练样本的真实值</li><li>h (x_i) 为第 i 个训练样本特征值组合预测函数</li><li>又称最小二乘法</li></ul><h3 id="优化算法"><a class="anchor" href="#优化算法">#</a> 优化算法</h3><p><strong>如何去求模型当中的 W，使得损失最小？（目的是找到最小损失对应的 W 值）</strong></p><p>线性回归经常使用的两种优化算法</p><ul><li>正规方程</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052103328.png" alt="正规方程"></p><blockquote><p>理解：X 为特征值矩阵，y 为目标值矩阵。直接求到最好的结果</p><p>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</p></blockquote><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052107712.png" alt="损失行数求解1"></p><ul><li><strong>梯度下降 (Gradient Descent)</strong></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052108246.png" alt="梯度下降公式"></p><blockquote><p>理解：α 为学习速率，需要手动指定（超参数），α 旁边的整体表示方向</p><p>沿着这个函数下降的方向找，最后就能找到山谷的最低点，然后更新 W 值</p><p>使用：面对训练数据规模十分庞大的任务 ，能够找到较好的结果</p></blockquote><p>我们通过两个图更好理解梯度下降的过程</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052109456.png" alt="单变量的梯度下降"></p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052109622.png" alt="多变量的梯度下降"></p><p><strong>所以有了梯度下降这样一个优化算法，回归就有了 &quot;自动学习&quot; 的能力</strong></p><h3 id="优化动态图演示"><a class="anchor" href="#优化动态图演示">#</a> 优化动态图演示</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052109870.gif" alt="线性回归优化动态图"></p><h3 id="线性回归api"><a class="anchor" href="#线性回归api">#</a> 线性回归 API</h3><ul><li>sklearn.linear_model.LinearRegression(fit_intercept=True)<ul><li>通过正规方程优化</li><li>fit_intercept：是否计算偏置</li><li>LinearRegression.coef_：回归系数</li><li>LinearRegression.intercept_：偏置</li></ul></li><li>sklearn.linear_model.SGDRegressor(loss=&quot;squared_loss&quot;, fit_intercept=True, learning_rate ='invscaling', eta0=0.01)<ul><li>SGDRegressor 类实现了随机梯度下降学习，它支持不同的<strong> loss 函数和正则化惩罚项</strong>来拟合线性回归模型。</li><li>loss: 损失类型<ul><li><strong>loss=”squared_loss”: 普通最小二乘法</strong></li></ul></li><li>fit_intercept：是否计算偏置</li><li>learning_rate : string, optional<ul><li>学习率填充</li><li><strong>'constant': eta = eta0</strong></li><li><strong>'optimal': eta = 1.0 / (alpha * (t + t0)) [default]</strong></li><li>'invscaling': eta = eta0 / pow(t, power_t)<ul><li><strong>power_t=0.25: 存在父类当中</strong></li></ul></li><li><strong>对于一个常数值的学习率来说，可以使用 learning_rate=’constant’ ，并使用 eta0 来指定学习率。</strong></li></ul></li><li>SGDRegressor.coef_：回归系数</li><li>SGDRegressor.intercept_：偏置</li></ul></li></ul><blockquote><p>sklearn 提供给我们两种实现的 API， 可以根据选择使用</p></blockquote><h3 id="分析-3"><a class="anchor" href="#分析-3">#</a> 分析</h3><p>回归当中的数据大小不一致，是否会导致结果影响较大。所以需要做标准化处理。同时我们对目标值也需要做标准化处理。</p><ul><li>数据分割与标准化处理</li><li>回归预测</li><li>线性回归的算法效果评估</li></ul><h3 id="回归性能评估"><a class="anchor" href="#回归性能评估">#</a> 回归性能评估</h3><p>均方误差 (Mean Squared Error) MSE) 评价机制：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052122771.png" alt="线性回归评估"></p><blockquote><p>注：y^i 为预测值，¯y 为真实值</p></blockquote><ul><li>sklearn.metrics.mean_squared_error(y_true, y_pred)<ul><li>均方误差回归损失</li><li>y_true: 真实值</li><li>y_pred: 预测值</li><li>return: 浮点数结果</li></ul></li></ul><h3 id="代码-4"><a class="anchor" href="#代码-4">#</a> 代码</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">mylinearregression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    线性回归预测房子价格</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    lb <span class="token operator">=</span> load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token comment"># print(lb.data)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># print(lb.target)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 对数据集进行划分</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>lb<span class="token punctuation">.</span>data<span class="token punctuation">,</span> lb<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment"># 需要做标准化处理对于特征值处理</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    std_x <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    x_train <span class="token operator">=</span> std_x<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    x_test <span class="token operator">=</span> std_x<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token comment"># print(x_train)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token comment"># 对于目标值进行标准化</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    std_y <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>    y_train <span class="token operator">=</span> std_y<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    y_test <span class="token operator">=</span> std_y<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    y_test <span class="token operator">=</span> std_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token comment"># 使用线性模型进行预测</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token comment"># 使用正规方程求解</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    lr <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token comment"># # 此时在干什么？</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre></pre></td></tr><tr><td data-num="35"></td><td><pre>    y_lr_predict <span class="token operator">=</span> std_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>lr<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正规方程预测的结果为："</span><span class="token punctuation">,</span> y_lr_predict<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正规方程的均方误差为："</span><span class="token punctuation">,</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_lr_predict<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token comment"># 梯度下降进行预测</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    sgd <span class="token operator">=</span> SGDRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="46"></td><td><pre>    sgd<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"SGD的权重参数为："</span><span class="token punctuation">,</span> sgd<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    y_sgd_predict <span class="token operator">=</span> std_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>sgd<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"SGD的预测的结果为："</span><span class="token punctuation">,</span> y_sgd_predict<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre>    <span class="token comment">#</span></pre></td></tr><tr><td data-num="53"></td><td><pre>    <span class="token comment"># # 怎么评判这两个方法好坏</span></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"SGD的均方误差为："</span><span class="token punctuation">,</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_sgd_predict<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="55"></td><td><pre></pre></td></tr><tr><td data-num="56"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="正规方程和梯度下降对比"><a class="anchor" href="#正规方程和梯度下降对比">#</a> 正规方程和梯度下降对比</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110052125273.png" alt="正规方程和梯度下降对比"></p><ul><li>文字对比</li></ul><table><thead><tr><th style="text-align:center">梯度下降</th><th style="text-align:center">正规方程</th></tr></thead><tbody><tr><td style="text-align:center">需要选择学习率</td><td style="text-align:center">不需要</td></tr><tr><td style="text-align:center">需要迭代求解</td><td style="text-align:center">一次运算得出</td></tr><tr><td style="text-align:center">特征数量较大可以使用</td><td style="text-align:center">需要计算方程，时间复杂度高 O (n3)</td></tr></tbody></table><ul><li>选择：<ul><li>小规模数据：<ul><li><strong>LinearRegression (不能解决拟合问题)</strong></li><li>岭回归</li></ul></li><li>大规模数据：SGDRegressor</li></ul></li></ul><h3 id="拓展-关于优化方法gd-sgd-sag"><a class="anchor" href="#拓展-关于优化方法gd-sgd-sag">#</a> 拓展 - 关于优化方法 GD、SGD、SAG</h3><h4 id="gd"><a class="anchor" href="#gd">#</a> GD</h4><p><strong>梯度下降 (Gradient Descent)，原始的梯度下降法需要计算所有样本的值才能够得出梯度，计算量大，所以后面才有会一系列的改进。</strong></p><h4 id="sgd"><a class="anchor" href="#sgd">#</a> SGD</h4><p><strong>随机梯度下降 (Stochastic gradient descent) 是一个优化方法。它在一次迭代时只考虑一个训练样本。</strong></p><ul><li>SGD 的优点是：<ul><li>高效</li><li>容易实现</li></ul></li><li>SGD 的缺点是：<ul><li>SGD 需要许多超参数：比如正则项参数、迭代数。</li><li>SGD 对于特征标准化是敏感的。</li></ul></li></ul><h4 id="sag"><a class="anchor" href="#sag">#</a> SAG</h4><p>随机平均梯度法 (Stochasitc Average Gradient)，由于收敛的速度太慢，有人提出 SAG 等基于梯度下降的算法</p><blockquote><p>Scikit-learn：SGDRegressor、岭回归、逻辑回归等当中都会有 SAG 优化</p></blockquote><h2 id="欠拟合与过拟合"><a class="anchor" href="#欠拟合与过拟合">#</a> 欠拟合与过拟合</h2><h3 id="定义-2"><a class="anchor" href="#定义-2">#</a> 定义</h3><ul><li>过拟合：一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。(模型过于复杂)</li><li>欠拟合：一个假设在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象。(模型过于简单)</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211518735.png" alt="欠拟合过拟合图示"></p><h3 id="原因以及解决办法"><a class="anchor" href="#原因以及解决办法">#</a> 原因以及解决办法</h3><ul><li>欠拟合原因以及解决办法<ul><li>原因：学习到数据的特征过少</li><li>解决办法：增加数据的特征数量</li></ul></li><li>过拟合原因以及解决办法<ul><li>原因：原始特征过多，存在一些嘈杂特征， 模型过于复杂是因为模型尝试去兼顾各个测试数据点</li><li>解决办法：<ul><li>正则化</li></ul></li></ul></li></ul><blockquote><p>在这里针对回归，我们选择了正则化。但是对于其他机器学习算法如分类算法来说也会出现这样的问题，除了一些算法本身作用之外（决策树、神经网络），我们更多的也是去自己做特征选择，包括之前说的删除、合并一些特征</p></blockquote><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211523717.png" alt="模型复杂"></p><h4 id="如何解决"><a class="anchor" href="#如何解决">#</a> 如何解决？</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211523371.png" alt="正则化"></p><blockquote><p>在学习的时候，数据提供的特征有些影响模型复杂度或者这个特征的数据点异常较多，所以算法在学习的时候尽量减少这个特征的影响（甚至删除某个特征的影响），这就是正则化</p><p>注：调整时候，算法并不知道某个特征影响，而是去调整参数得出优化的结果</p></blockquote><h3 id="正则化类别"><a class="anchor" href="#正则化类别">#</a> 正则化类别</h3><ul><li>L2 正则化<ul><li>作用：可以使得其中一些 W 的都很小，都接近于 0，削弱某个特征的影响</li><li>优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象</li><li>Ridge 回归</li></ul></li><li>L1 正则化<ul><li>作用：可以使得其中一些 W 的值直接为 0，删除这个特征的影响</li><li>LASSO 回归</li></ul></li></ul><h2 id="线性回归的改进-岭回归"><a class="anchor" href="#线性回归的改进-岭回归">#</a> 线性回归的改进 - 岭回归</h2><h3 id="带有l2正则化的线性回归-岭回归"><a class="anchor" href="#带有l2正则化的线性回归-岭回归">#</a> 带有 L2 正则化的线性回归 - 岭回归</h3><p>岭回归，其实也是一种线性回归。只不过在算法建立回归方程时候，加上正则化的限制，从而达到解决过拟合的效果</p><h3 id="api-5"><a class="anchor" href="#api-5">#</a> API</h3><ul><li>sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True,solver=&quot;auto&quot;, normalize=False)<ul><li>具有 l2 正则化的线性回归</li><li>alpha: 正则化力度，也叫 λ<ul><li><strong>λ 取值：0~1 1~10</strong></li></ul></li><li>solver: 会根据数据自动选择优化方法<ul><li><strong>sag: 如果数据集、特征都比较大，选择该随机梯度下降优化</strong></li></ul></li><li>normalize: 数据是否进行标准化<ul><li>normalize=False: 可以在 fit 之前调用 preprocessing.StandardScaler 标准化数据</li></ul></li><li>Ridge.coef_: 回归权重</li><li>Ridge.intercept_: 回归偏置</li></ul></li></ul><blockquote><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>All last four solvers support both dense <span class="token keyword">and</span> sparse data<span class="token punctuation">.</span> However<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="2"></td><td><pre>only <span class="token string">'sag'</span> supports sparse <span class="token builtin">input</span> when `fit_intercept` <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">.</span></pre></td></tr></table></figure></blockquote><h5 id="ridge方法相当于sgdregressorpenaltyl2-losssquared_loss只不过sgdregressor实现了一个普通的随机梯度下降学习推荐使用ridge实现了sag"><a class="anchor" href="#ridge方法相当于sgdregressorpenaltyl2-losssquared_loss只不过sgdregressor实现了一个普通的随机梯度下降学习推荐使用ridge实现了sag">#</a> Ridge 方法相当于 SGDRegressor (penalty='l2', loss=&quot;squared_loss&quot;), 只不过 SGDRegressor 实现了一个普通的随机梯度下降学习，推荐使用 Ridge (实现了 SAG)</h5><ul><li>sklearn.linear_model.RidgeCV(_BaseRidgeCV, RegressorMixin)<ul><li>具有 l2 正则化的线性回归，可以进行交叉验证</li><li>coef_: 回归系数</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">_BaseRidgeCV</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> alphas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>                 fit_intercept<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>                 cv<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> gcv_mode<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                 store_cv_values<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr></table></figure><h3 id="观察正则化程度的变化对结果的影响"><a class="anchor" href="#观察正则化程度的变化对结果的影响">#</a> 观察正则化程度的变化，对结果的影响？</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211614701.png" alt="正则化力度"></p><ul><li>正则化力度越大，权重系数会越小</li><li>正则化力度越小，权重系数会越大</li></ul><h3 id="波士顿房价预测"><a class="anchor" href="#波士顿房价预测">#</a> 波士顿房价预测</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>rd <span class="token operator">=</span> Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>rd<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"岭回归的权重参数为："</span><span class="token punctuation">,</span> rd<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>y_rd_predict <span class="token operator">=</span> std_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>rd<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"岭回归的预测的结果为："</span><span class="token punctuation">,</span> y_rd_predict<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"岭回归的均方误差为："</span><span class="token punctuation">,</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_rd_predict<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="分类算法-逻辑回归与二分类"><a class="anchor" href="#分类算法-逻辑回归与二分类">#</a> 分类算法 - 逻辑回归与二分类</h2><h3 id="逻辑回归的原理"><a class="anchor" href="#逻辑回归的原理">#</a> 逻辑回归的原理</h3><blockquote><p>逻辑回归（Logistic Regression）是机器学习中的一种分类模型，逻辑回归是一种分类算法，虽然名字中带有回归，但是它与回归之间有一定的联系。</p></blockquote><h4 id="输入"><a class="anchor" href="#输入">#</a> 输入</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211617961.png" alt=""></p><p>逻辑回归的输入就是一个线性回归的结果。</p><h4 id="激活函数"><a class="anchor" href="#激活函数">#</a> 激活函数</h4><ul><li>sigmoid 函数</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211617300.png" alt="sigmoid公式"></p><ul><li>分析<ul><li>回归的结果输入到 sigmoid 函数当中</li><li>输出结果：[0, 1] 区间中的一个概率值，默认为 0.5 为阈值</li></ul></li></ul><blockquote><p>逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为 1 (正例), 另外的一个类别会标记为 0 (反例)。（方便损失计算）</p></blockquote><h5 id="输出结果解释重要假设有两个类别ab并且假设我们的概率值为属于a1这个类别的概率值-现在有一个样本的输入到逻辑回归输出结果06那么这个概率值超过05意味着我们训练或者预测的结果就是a1类别-那么反之如果得出结果为03那么训练或者预测结果就为b0类别"><a class="anchor" href="#输出结果解释重要假设有两个类别ab并且假设我们的概率值为属于a1这个类别的概率值-现在有一个样本的输入到逻辑回归输出结果06那么这个概率值超过05意味着我们训练或者预测的结果就是a1类别-那么反之如果得出结果为03那么训练或者预测结果就为b0类别">#</a> 输出结果解释 (重要)：假设有两个类别 A，B，并且假设我们的概率值为属于 A (1) 这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果 0.6，那么这个概率值超过 0.5，意味着我们训练或者预测的结果就是 A (1) 类别。那么反之，如果得出结果为 0.3 那么，训练或者预测结果就为 B (0) 类别。</h5><h5 id="所以接下来我们回忆之前的线性回归预测结果我们用均方误差衡量那如果对于逻辑回归我们预测的结果不对该怎么去衡量这个损失呢我们来看这样一张图"><a class="anchor" href="#所以接下来我们回忆之前的线性回归预测结果我们用均方误差衡量那如果对于逻辑回归我们预测的结果不对该怎么去衡量这个损失呢我们来看这样一张图">#</a> 所以接下来我们回忆之前的线性回归预测结果我们用均方误差衡量，那如果对于逻辑回归，我们预测的结果不对该怎么去衡量这个损失呢？我们来看这样一张图</h5><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211617262.png" alt="逻辑回归运算过程"></p><p>那么如何去衡量逻辑回归的预测结果与真实结果的差异呢？</p><h3 id="损失以及优化"><a class="anchor" href="#损失以及优化">#</a> 损失以及优化</h3><h4 id="损失"><a class="anchor" href="#损失">#</a> 损失</h4><p>逻辑回归的损失，称之为<strong>对数似然损失</strong>，公式如下：</p><ul><li>分开类别：</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211631735.png" alt="单个对数似然损失"></p><p>怎么理解单个的式子呢？这个要根据 log 的函数图像来理解</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211631366.png" alt="单个损失解释"></p><ul><li>综合完整损失函数</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211631991.png" alt="完整对数似然损失"></p><blockquote><p>看到这个式子，其实跟我们讲的信息熵类似。</p></blockquote><p>接下来我们呢就带入上面那个例子来计算一遍，就能理解意义了。</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211631731.png" alt="损失计算过程"></p><blockquote><p>我们已经知道，log (P), P 值越大，结果越小，所以我们可以对着这个损失的式子去分析</p></blockquote><h4 id="优化"><a class="anchor" href="#优化">#</a> 优化</h4><p>同样使用梯度下降优化算法，去减少损失函数的值。这样去更新逻辑回归前面对应算法的权重参数，<strong>提升原本属于 1 类别的概率，降低原本是 0 类别的概率。</strong></p><h3 id="逻辑回归api"><a class="anchor" href="#逻辑回归api">#</a> 逻辑回归 API</h3><ul><li>sklearn.linear_model.LogisticRegression(solver='liblinear', penalty=‘l2’, C = 1.0)<ul><li>solver: 优化求解方式（默认开源的 liblinear 库实现，内部使用了坐标轴下降法来迭代优化损失函数）<ul><li>sag：根据数据集自动选择，随机平均梯度下降</li></ul></li><li>penalty：正则化的种类</li><li>C：正则化力度</li></ul></li></ul><blockquote><p><strong>默认将类别数量少的当做正例</strong></p></blockquote><h5 id="logisticregression方法相当于-sgdclassifierlosslog-penalty-sgdclassifier实现了一个普通的随机梯度下降学习也支持平均随机梯度下降法asgd可以通过设置averagetrue-而使用logisticregression实现了sag"><a class="anchor" href="#logisticregression方法相当于-sgdclassifierlosslog-penalty-sgdclassifier实现了一个普通的随机梯度下降学习也支持平均随机梯度下降法asgd可以通过设置averagetrue-而使用logisticregression实现了sag">#</a> LogisticRegression 方法相当于 SGDClassifier (loss=&quot;log&quot;, penalty=&quot; &quot;),SGDClassifier 实现了一个普通的随机梯度下降学习，也支持平均随机梯度下降法（ASGD），可以通过设置 average=True。而使用 LogisticRegression (实现了 SAG)</h5><h3 id="案例癌症分类预测-良恶性乳腺癌肿瘤预测"><a class="anchor" href="#案例癌症分类预测-良恶性乳腺癌肿瘤预测">#</a> 案例：癌症分类预测 - 良／恶性乳腺癌肿瘤预测</h3><ul><li>数据介绍</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211641873.png" alt="癌症数据"></p><p>原始数据的下载地址：<span class="exturl" data-url="aHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2JyZWFzdC1jYW5jZXItd2lzY29uc2luLw==">https://archive.ics.uci.edu/ml/machine-learning-databases/</span></p><blockquote><p>数据描述</p><p>（1）699 条样本，共 11 列数据，第一列用语检索的 id，后 9 列分别是与肿瘤</p><p>相关的医学特征，最后一列表示肿瘤类型的数值。</p><p>（2）包含 16 个缺失值，用”?” 标出。</p></blockquote><h3 id="分析-4"><a class="anchor" href="#分析-4">#</a> 分析</h3><ul><li>缺失值处理</li><li>标准化处理</li><li>逻辑回归预测</li></ul><h3 id="代码-5"><a class="anchor" href="#代码-5">#</a> 代码</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">logisticregression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    逻辑回归进行癌症预测</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 1、读取数据，处理缺失值以及标准化</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    column_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Sample code number'</span><span class="token punctuation">,</span> <span class="token string">'Clump Thickness'</span><span class="token punctuation">,</span> <span class="token string">'Uniformity of Cell Size'</span><span class="token punctuation">,</span> <span class="token string">'Uniformity of Cell Shape'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                   <span class="token string">'Marginal Adhesion'</span><span class="token punctuation">,</span> <span class="token string">'Single Epithelial Cell Size'</span><span class="token punctuation">,</span> <span class="token string">'Bare Nuclei'</span><span class="token punctuation">,</span> <span class="token string">'Bland Chromatin'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                   <span class="token string">'Normal Nucleoli'</span><span class="token punctuation">,</span> <span class="token string">'Mitoses'</span><span class="token punctuation">,</span> <span class="token string">'Class'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>                       names<span class="token operator">=</span>column_name<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token comment"># 删除缺失值</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>to_replace<span class="token operator">=</span><span class="token string">'?'</span><span class="token punctuation">,</span> value<span class="token operator">=</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment"># 取出特征值</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    x <span class="token operator">=</span> data<span class="token punctuation">[</span>column_name<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>    y <span class="token operator">=</span> data<span class="token punctuation">[</span>column_name<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment"># 分割数据集</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment"># 进行标准化</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    std <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    x_train <span class="token operator">=</span> std<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>    x_test <span class="token operator">=</span> std<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token comment"># 使用逻辑回归</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>    lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"得出来的权重："</span><span class="token punctuation">,</span> lr<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token comment"># 预测类别</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测的类别："</span><span class="token punctuation">,</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>    <span class="token comment"># 得出准确率</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测的准确率:"</span><span class="token punctuation">,</span> lr<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="分类的评估方法"><a class="anchor" href="#分类的评估方法">#</a> 分类的评估方法</h3><h4 id="精确率与召回率"><a class="anchor" href="#精确率与召回率">#</a> 精确率与召回率</h4><h5 id="混淆矩阵"><a class="anchor" href="#混淆矩阵">#</a> 混淆矩阵</h5><p>在分类任务下，预测结果 (Predicted Condition) 与正确标记 (True Condition) 之间存在四种不同的组合，构成混淆矩阵 (适用于多分类)</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211700329.png" alt="混淆矩阵"></p><h5 id="精确率precision与召回率recall"><a class="anchor" href="#精确率precision与召回率recall">#</a> 精确率 (Precision) 与召回率 (Recall)</h5><ul><li>精确率：预测结果为正例样本中真实为正例的比例（了解）</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211701104.png" alt="精确率"></p><ul><li>召回率：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211701338.png" alt="召回率"></p><p>那么怎么更好理解这个两个概念</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211701280.png" alt="精确率与召回率理解"></p><p>还有其他的评估标准，F1-score，反映了模型的稳健型</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211702028.png" alt="F1"></p><h5 id="分类评估报告api"><a class="anchor" href="#分类评估报告api">#</a> 分类评估报告 API</h5><ul><li>sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None )</li><li><ul><li>y_true：真实目标值</li><li>y_pred：估计器预测目标值</li><li>labels: 指定类别对应的数字</li><li>target_names：目标类别名称</li><li>return：每个类别精确率与召回率</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"精确率和召回率为："</span><span class="token punctuation">,</span> classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'良性'</span><span class="token punctuation">,</span> <span class="token string">'恶性'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><strong>假设这样一个情况，如果 99 个样本癌症，1 个样本非癌症，不管怎样我全都预测正例 (默认癌症为正例), 准确率就为 99% 但是这样效果并不好，这就是样本不均衡下的评估问题</strong></p><h4 id="问题如何衡量样本不均衡下的评估"><a class="anchor" href="#问题如何衡量样本不均衡下的评估">#</a> 问题：如何衡量样本不均衡下的评估？</h4><h4 id="roc曲线与auc指标"><a class="anchor" href="#roc曲线与auc指标">#</a> ROC 曲线与 AUC 指标</h4><h5 id="知道tpr与fpr"><a class="anchor" href="#知道tpr与fpr">#</a> 知道 TPR 与 FPR</h5><ul><li>TPR = TP / (TP + FN)<ul><li>所有真实类别为 1 的样本中，预测类别为 1 的比例</li></ul></li><li>FPR = FP / (FP + FN)<ul><li>所有真实类别为 0 的样本中，预测类别为 1 的比例</li></ul></li></ul><h5 id="roc曲线"><a class="anchor" href="#roc曲线">#</a> ROC 曲线</h5><ul><li>ROC 曲线的横轴就是 FPRate，纵轴就是 TPRate，当二者相等时，表示的意义则是：对于不论真实类别是 1 还是 0 的样本，分类器预测为 1 的概率是相等的，此时 AUC 为 0.5</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211702640.png" alt="ROC"></p><h5 id="auc指标"><a class="anchor" href="#auc指标">#</a> AUC 指标</h5><ul><li>AUC 的概率意义是随机取一对正负样本，正样本得分大于负样本的概率</li><li>AUC 的最小值为 0.5，最大值为 1，取值越高越好</li><li><strong>AUC=1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。</strong></li><li><strong>0.5&lt;AUC&lt;1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</strong></li></ul><blockquote><p><strong>最终 AUC 的范围在 [0.5, 1] 之间，并且越接近 1 越好</strong></p></blockquote><h5 id="auc计算api"><a class="anchor" href="#auc计算api">#</a> AUC 计算 API</h5><ul><li>from sklearn.metrics import roc_auc_score<ul><li>sklearn.metrics.roc_auc_score(y_true, y_score)<ul><li>计算 ROC 曲线面积，即 AUC 值</li><li>y_true: 每个样本的真实类别，必须为 0 (反例),1 (正例) 标记</li><li>y_score: 每个样本预测的概率值</li></ul></li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 0.5~1 之间，越接近于 1 约好</span></pre></td></tr><tr><td data-num="2"></td><td><pre>y_test <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_test <span class="token operator">></span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AUC指标："</span><span class="token punctuation">,</span> roc_auc_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h5 id="总结"><a class="anchor" href="#总结">#</a> 总结</h5><ul><li>AUC 只能用来评价二分类</li><li>AUC 非常适合评价样本不平衡中的分类器性能</li></ul><h2 id="模型保存和加载"><a class="anchor" href="#模型保存和加载">#</a> 模型保存和加载</h2><h3 id="1-sklearn模型的保存和加载api"><a class="anchor" href="#1-sklearn模型的保存和加载api">#</a> 1、sklearn 模型的保存和加载 API</h3><ul><li>from sklearn.externals import joblib<ul><li>保存：joblib.dump (rf, 'test.pkl')</li><li>加载：estimator = joblib.load ('test.pkl')</li></ul></li></ul><h3 id="2-线性回归的模型保存加载案例"><a class="anchor" href="#2-线性回归的模型保存加载案例">#</a> 2、线性回归的模型保存加载案例</h3><ul><li>保存</li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 使用线性模型进行预测</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 使用正规方程求解</span></pre></td></tr><tr><td data-num="3"></td><td><pre>lr <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 此时在干什么？</span></pre></td></tr><tr><td data-num="5"></td><td><pre>lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 保存训练完结束的模型</span></pre></td></tr><tr><td data-num="7"></td><td><pre>joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>lr<span class="token punctuation">,</span> <span class="token string">"test.pkl"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ul><li>加载</li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 通过已有的模型去预测房价</span></pre></td></tr><tr><td data-num="2"></td><td><pre>model <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"test.pkl"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"从文件加载进来的模型预测房价的结果："</span><span class="token punctuation">,</span> std_y<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="无监督学习-k-means算法"><a class="anchor" href="#无监督学习-k-means算法">#</a> 无监督学习 - K-means 算法</h2><h3 id="1-什么是无监督学习"><a class="anchor" href="#1-什么是无监督学习">#</a> 1、 什么是无监督学习</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211710955.png" alt="人员聚类"></p><ul><li>一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户可以通过有关联的广告接触到他们的目标客户。</li><li>Airbnb 需要将自己的房屋清单分组成不同的社区，以便用户能更轻松地查阅这些清单。</li><li>一个数据科学团队需要降低一个大型数据集的维度的数量，以便简化建模和降低文件大小。</li></ul><p>我们可以怎样最有用地对其进行归纳和分组？我们可以怎样以一种压缩格式有效地表征数据？<strong>这都是无监督学习的目标，之所以称之为无监督，是因为这是从无标签的数据开始学习的。</strong></p><h3 id="2-无监督学习包含算法"><a class="anchor" href="#2-无监督学习包含算法">#</a> 2、 无监督学习包含算法</h3><ul><li>聚类<ul><li>K-means (K 均值聚类)</li></ul></li><li>降维<ul><li>PCA</li></ul></li></ul><h3 id="3-k-means原理"><a class="anchor" href="#3-k-means原理">#</a> 3、 K-means 原理</h3><p>我们先来看一下一个 K-means 的聚类效果图</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211710799.png" alt="K-means如何聚类效果"></p><h4 id="31-k-means聚类步骤"><a class="anchor" href="#31-k-means聚类步骤">#</a> 3.1 K-means 聚类步骤</h4><ul><li>1、随机设置 K 个特征空间内的点作为初始的聚类中心</li><li>2、对于其他每个点计算到 K 个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</li><li>3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</li><li>4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程</li></ul><p>我们以一张图来解释效果</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211710386.png" alt="K-means过程分析"></p><h3 id="4-k-meansapi"><a class="anchor" href="#4-k-meansapi">#</a> 4、K-meansAPI</h3><ul><li>sklearn.cluster.KMeans(n_clusters=8,init=‘k-means++’)<ul><li>k-means 聚类</li><li>n_clusters: 开始的聚类中心数量</li><li>init: 初始化方法，默认为 'k-means ++’</li><li>labels_: 默认标记的类型，可以和真实值比较（不是值比较）</li></ul></li></ul><h3 id="5-案例k-means对instacart-market用户聚类"><a class="anchor" href="#5-案例k-means对instacart-market用户聚类">#</a> 5、 案例：k-means 对 Instacart Market 用户聚类</h3><h4 id="51-分析"><a class="anchor" href="#51-分析">#</a> 5.1 分析</h4><ul><li>1、降维之后的数据</li><li>2、k-means 聚类</li><li>3、聚类结果显示</li></ul><h4 id="52-代码"><a class="anchor" href="#52-代码">#</a> 5.2 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 取 500 个用户进行测试</span></pre></td></tr><tr><td data-num="2"></td><td><pre>cust <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">500</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>km <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>km<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>cust<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>pre <span class="token operator">=</span> km<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>cust<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="问题如何去评估聚类的效果呢"><a class="anchor" href="#问题如何去评估聚类的效果呢">#</a> 问题：如何去评估聚类的效果呢？</h4><h3 id="6-kmeans性能评估指标"><a class="anchor" href="#6-kmeans性能评估指标">#</a> 6、Kmeans 性能评估指标</h3><h4 id="61-轮廓系数"><a class="anchor" href="#61-轮廓系数">#</a> 6.1 轮廓系数</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211711780.png" alt="轮廓系数公式"></p><blockquote><p>注：对于每个点 i 为已聚类数据中的样本 ，b_i 为 i 到其它族群的所有样本的距离最小值，a_i 为 i 到本身簇的距离平均值。最终计算出所有的样本点的轮廓系数平均值</p></blockquote><h4 id="62-轮廓系数值分析"><a class="anchor" href="#62-轮廓系数值分析">#</a> 6.2 轮廓系数值分析</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110211711297.png" alt="img"></p><ul><li>分析过程（我们以一个蓝 1 点为例）<ul><li>1、计算出蓝 1 离本身族群所有点的距离的平均值 a_i</li><li>2、蓝 1 到其它两个族群的距离计算出平均值红平均，绿平均，取最小的那个距离作为 b_i</li><li>根据公式：极端值考虑：如果 b_i &gt;&gt;a_i: 那么公式结果趋近于 1；如果 a_i&gt;&gt;&gt;b_i: 那么公式结果趋近于 - 1</li></ul></li></ul><h4 id="63-结论"><a class="anchor" href="#63-结论">#</a> 6.3 结论</h4><p><strong>如果 b_i&gt;&gt;a_i: 趋近于 1 效果越好， b_i&lt;&lt;a_i: 趋近于 - 1，效果不好。轮廓系数的值是介于 [-1,1] ，越趋近于 1 代表内聚度和分离度都相对较优。</strong></p><h4 id="64-轮廓系数api"><a class="anchor" href="#64-轮廓系数api">#</a> 6.4 轮廓系数 API</h4><ul><li>sklearn.metrics.silhouette_score(X, labels)<ul><li>计算所有样本的平均轮廓系数</li><li>X：特征值</li><li>labels：被聚类标记的目标值</li></ul></li></ul><h4 id="65-用户聚类结果评估"><a class="anchor" href="#65-用户聚类结果评估">#</a> 6.5 用户聚类结果评估</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>silhouette_score<span class="token punctuation">(</span>cust<span class="token punctuation">,</span> pre<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="7-k-means总结"><a class="anchor" href="#7-k-means总结">#</a> 7、K-means 总结</h3><ul><li>特点分析：采用迭代式算法，直观易懂并且非常实用</li><li>缺点：容易收敛到局部最优解 (多次聚类)</li></ul><blockquote><p>注意：聚类一般做在分类之前</p></blockquote><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 机器学习</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-10-21 17:13:42" itemprop="dateModified" datetime="2021-10-21T17:13:42+08:00">2021-10-21</time> </span><span id="2021/08/26/机器学习/机器学习基础/" class="item leancloud_visitors" data-flag-title="机器学习基础" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="lzs 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="lzs 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>lzs <i class="ic i-at"><em>@</em></i>Sakura</li><li class="link"><strong>本文链接：</strong> <a href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习基础">https://zengshengli775.gitee.io/2021/08/26/机器学习/机器学习基础/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2021/08/25/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/Mac%20VScode%E5%BF%AB%E6%8D%B7%E9%94%AE/" itemprop="url" rel="prev" data-background-image="http:&#x2F;&#x2F;www.dmoe.cc&#x2F;random.php?358291" title="Mac VScode快捷键"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 实用技巧</span><h3>Mac VScode快捷键</h3></a></div><div class="item right"><a href="/2021/08/26/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/PS4%E4%BB%A3%E7%90%86%E4%B8%8A%E7%BD%91/" itemprop="url" rel="next" data-background-image="http:&#x2F;&#x2F;www.dmoe.cc&#x2F;random.php?839434" title="PS4代理上网"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 实用技巧</span><h3>PS4代理上网</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">李宏毅机器学习笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%983%E5%A4%A9%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.</span> <span class="toc-text">黑马程序员 3 天快速入门 python 机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E9%A9%AC-3%E5%A4%A9%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-html"><span class="toc-number">3.</span> <span class="toc-text">[黑马] 3 天快速入门 python 机器学习 - html</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0"><span class="toc-number"></span> <span class="toc-text">1. 机器学习概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">1.1 什么是机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">1.2 机器学习算法分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">1.3 开发流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number"></span> <span class="toc-text">2. 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">2.1 数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#211-%E5%8F%AF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text">2.1.1 可用数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#212-sklearn"><span class="toc-number">1.2.</span> <span class="toc-text">2.1.2 sklearn</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">2.2 特征工程介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96"><span class="toc-number">3.</span> <span class="toc-text">2.3 特征抽取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#232-%E5%AD%97%E5%85%B8%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.1.</span> <span class="toc-text">2.3.2 字典特征提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#233-%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text">2.3.3 文本特征提取</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2331sklearnfeature_extractiontextcountvectorizerstop_words%E8%BF%94%E5%9B%9E%E8%AF%8D%E9%A2%91%E7%9F%A9%E9%98%B5%E7%BB%9F%E8%AE%A1%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%89%B9%E5%BE%81%E8%AF%8D%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%AA%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.3.3.1.sklearn.feature_extraction.text.CountVectorizer(stop_words&#x3D;[])	返回词频矩阵，统计每个样本特征词出现的个数。</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#23311%E5%AF%B9%E8%8B%B1%E6%96%87%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">2.3.3.1.1 对英文进行特征提取</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#23312%E5%AF%B9%E4%B8%AD%E6%96%87%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">2.3.3.1.2 对中文进行特征提取</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2332sklearnfeature_extractiontexttfidfvectorizer%E7%94%A8%E4%BB%A5%E8%AF%84%E4%BC%B0%E4%B8%80%E5%AD%97%E8%AF%8D%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E9%9B%86%E6%88%96%E4%B8%80%E4%B8%AA%E8%AF%AD%E6%96%99%E5%BA%93%E4%B8%AD%E7%9A%84%E5%85%B6%E4%B8%AD%E4%B8%80%E4%BB%BD%E6%96%87%E4%BB%B6%E7%9A%84%E9%87%8D%E8%A6%81%E7%A8%8B%E5%BA%A6"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.3.3.2.sklearn.feature_extraction.text.TfidfVectorizer	用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.</span> <span class="toc-text">2.4 特征预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#241%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">2.4.1 归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#242%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">4.2.</span> <span class="toc-text">2.4.2 标准化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="toc-number">5.</span> <span class="toc-text">2.5 特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#251-%E9%99%8D%E7%BB%B4"><span class="toc-number">5.1.</span> <span class="toc-text">2.5.1 降维</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#252%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">5.2.</span> <span class="toc-text">2.5.2 特征选择</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2521%E6%96%B9%E6%B3%95"><span class="toc-number">5.2.1.</span> <span class="toc-text">2.5.2.1 方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2522%E8%BF%87%E6%BB%A4%E5%BC%8F"><span class="toc-number">5.2.2.</span> <span class="toc-text">2.5.2.2 过滤式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#253%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-number">5.3.</span> <span class="toc-text">2.5.3 相关系数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca"><span class="toc-number">6.</span> <span class="toc-text">2.6 主成分分析 (PCA)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">3. 分类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">1.</span> <span class="toc-text">3.1 数据集介绍与划分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">1.1.</span> <span class="toc-text">数据集的划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api"><span class="toc-number">1.2.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.3.</span> <span class="toc-text">sklearn 数据集介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-2"><span class="toc-number">1.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%92%8C%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.5.</span> <span class="toc-text">分类和回归数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.6.</span> <span class="toc-text">返回类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8"><span class="toc-number">2.</span> <span class="toc-text">3.2sklearn 转换器和估计器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">2.1.</span> <span class="toc-text">1. 转换器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E4%BC%B0%E8%AE%A1%E5%99%A8sklearn%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.</span> <span class="toc-text">2. 估计器 (sklearn 机器学习算法的实现)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95knn"><span class="toc-number">3.</span> <span class="toc-text">3.3 K - 近邻算法 (KNN)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">距离公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95api"><span class="toc-number">3.3.</span> <span class="toc-text">K - 近邻算法 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE"><span class="toc-number">3.4.</span> <span class="toc-text">预测签到位置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">3.5.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">3.6.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="toc-number">4.</span> <span class="toc-text">3.4 模型选择与调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2grid-search"><span class="toc-number">4.1.</span> <span class="toc-text">超参数搜索 - 网格搜索 (Grid Search)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="toc-number">4.2.</span> <span class="toc-text">模型选择与调优</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8Bk%E5%80%BC%E8%B0%83%E4%BC%98"><span class="toc-number">4.3.</span> <span class="toc-text">Facebook 签到位置预测 K 值调优</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">3.5 朴素贝叶斯算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87"><span class="toc-number">5.1.</span> <span class="toc-text">条件概率与联合概率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F"><span class="toc-number">5.2.</span> <span class="toc-text">贝叶斯公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91%E7%B3%BB%E6%95%B0"><span class="toc-number">5.3.</span> <span class="toc-text">拉普拉斯平滑系数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-3"><span class="toc-number">5.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20%E7%B1%BB%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB"><span class="toc-number">5.5.</span> <span class="toc-text">20 类新闻分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90-2"><span class="toc-number">5.6.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-2"><span class="toc-number">5.7.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">6.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="toc-number">6.1.</span> <span class="toc-text">信息熵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%85%AC%E5%BC%8F"><span class="toc-number">6.2.</span> <span class="toc-text">信息增益 定义与公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%B8%89%E7%A7%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.3.</span> <span class="toc-text">决策树的三种算法实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91api"><span class="toc-number">6.4.</span> <span class="toc-text">决策树 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B"><span class="toc-number">6.5.</span> <span class="toc-text">泰坦尼克号乘客生存预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">6.6.</span> <span class="toc-text">可视化决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E5%88%B0dot%E6%96%87%E4%BB%B6"><span class="toc-number">6.7.</span> <span class="toc-text">保存树的结构到 dot 文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%BB%E7%BB%93"><span class="toc-number">6.8.</span> <span class="toc-text">决策树总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E4%B9%8B%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">7.</span> <span class="toc-text">集成学习方法之随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">7.1.</span> <span class="toc-text">集成学习方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">7.2.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8E%9F%E7%90%86%E8%BF%87%E7%A8%8B"><span class="toc-number">7.3.</span> <span class="toc-text">随机森林原理过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-4"><span class="toc-number">7.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-3"><span class="toc-number">7.5.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E4%B8%8E%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">回归与聚类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">1.</span> <span class="toc-text">线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%85%AC%E5%BC%8F"><span class="toc-number">1.1.</span> <span class="toc-text">定义与公式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">优化算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%8A%A8%E6%80%81%E5%9B%BE%E6%BC%94%E7%A4%BA"><span class="toc-number">4.</span> <span class="toc-text">优化动态图演示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92api"><span class="toc-number">5.</span> <span class="toc-text">线性回归 API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90-3"><span class="toc-number">6.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="toc-number">7.</span> <span class="toc-text">回归性能评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-4"><span class="toc-number">8.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AF%B9%E6%AF%94"><span class="toc-number">9.</span> <span class="toc-text">正规方程和梯度下降对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%93%E5%B1%95-%E5%85%B3%E4%BA%8E%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95gd-sgd-sag"><span class="toc-number">10.</span> <span class="toc-text">拓展 - 关于优化方法 GD、SGD、SAG</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#gd"><span class="toc-number">10.1.</span> <span class="toc-text">GD</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sgd"><span class="toc-number">10.2.</span> <span class="toc-text">SGD</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sag"><span class="toc-number">10.3.</span> <span class="toc-text">SAG</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number"></span> <span class="toc-text">欠拟合与过拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-2"><span class="toc-number">1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">原因以及解决办法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="toc-number">2.1.</span> <span class="toc-text">如何解决？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E7%B1%BB%E5%88%AB"><span class="toc-number">3.</span> <span class="toc-text">正则化类别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%94%B9%E8%BF%9B-%E5%B2%AD%E5%9B%9E%E5%BD%92"><span class="toc-number"></span> <span class="toc-text">线性回归的改进 - 岭回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6%E6%9C%89l2%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E5%B2%AD%E5%9B%9E%E5%BD%92"><span class="toc-number">1.</span> <span class="toc-text">带有 L2 正则化的线性回归 - 岭回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#api-5"><span class="toc-number">2.</span> <span class="toc-text">API</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ridge%E6%96%B9%E6%B3%95%E7%9B%B8%E5%BD%93%E4%BA%8Esgdregressorpenaltyl2-losssquared_loss%E5%8F%AA%E4%B8%8D%E8%BF%87sgdregressor%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8ridge%E5%AE%9E%E7%8E%B0%E4%BA%86sag"><span class="toc-number">2.0.1.</span> <span class="toc-text">Ridge 方法相当于 SGDRegressor (penalty&#x3D;&#39;l2&#39;, loss&#x3D;&quot;squared_loss&quot;), 只不过 SGDRegressor 实现了一个普通的随机梯度下降学习，推荐使用 Ridge (实现了 SAG)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%82%E5%AF%9F%E6%AD%A3%E5%88%99%E5%8C%96%E7%A8%8B%E5%BA%A6%E7%9A%84%E5%8F%98%E5%8C%96%E5%AF%B9%E7%BB%93%E6%9E%9C%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">3.</span> <span class="toc-text">观察正则化程度的变化，对结果的影响？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B"><span class="toc-number">4.</span> <span class="toc-text">波士顿房价预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E4%BA%8C%E5%88%86%E7%B1%BB"><span class="toc-number"></span> <span class="toc-text">分类算法 - 逻辑回归与二分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">逻辑回归的原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5"><span class="toc-number">1.1.</span> <span class="toc-text">输入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.2.</span> <span class="toc-text">激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%E8%A7%A3%E9%87%8A%E9%87%8D%E8%A6%81%E5%81%87%E8%AE%BE%E6%9C%89%E4%B8%A4%E4%B8%AA%E7%B1%BB%E5%88%ABab%E5%B9%B6%E4%B8%94%E5%81%87%E8%AE%BE%E6%88%91%E4%BB%AC%E7%9A%84%E6%A6%82%E7%8E%87%E5%80%BC%E4%B8%BA%E5%B1%9E%E4%BA%8Ea1%E8%BF%99%E4%B8%AA%E7%B1%BB%E5%88%AB%E7%9A%84%E6%A6%82%E7%8E%87%E5%80%BC-%E7%8E%B0%E5%9C%A8%E6%9C%89%E4%B8%80%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E8%BE%93%E5%85%A5%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C06%E9%82%A3%E4%B9%88%E8%BF%99%E4%B8%AA%E6%A6%82%E7%8E%87%E5%80%BC%E8%B6%85%E8%BF%8705%E6%84%8F%E5%91%B3%E7%9D%80%E6%88%91%E4%BB%AC%E8%AE%AD%E7%BB%83%E6%88%96%E8%80%85%E9%A2%84%E6%B5%8B%E7%9A%84%E7%BB%93%E6%9E%9C%E5%B0%B1%E6%98%AFa1%E7%B1%BB%E5%88%AB-%E9%82%A3%E4%B9%88%E5%8F%8D%E4%B9%8B%E5%A6%82%E6%9E%9C%E5%BE%97%E5%87%BA%E7%BB%93%E6%9E%9C%E4%B8%BA03%E9%82%A3%E4%B9%88%E8%AE%AD%E7%BB%83%E6%88%96%E8%80%85%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%B0%B1%E4%B8%BAb0%E7%B1%BB%E5%88%AB"><span class="toc-number">1.2.1.</span> <span class="toc-text">输出结果解释 (重要)：假设有两个类别 A，B，并且假设我们的概率值为属于 A (1) 这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果 0.6，那么这个概率值超过 0.5，意味着我们训练或者预测的结果就是 A (1) 类别。那么反之，如果得出结果为 0.3 那么，训练或者预测结果就为 B (0) 类别。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%80%E4%BB%A5%E6%8E%A5%E4%B8%8B%E6%9D%A5%E6%88%91%E4%BB%AC%E5%9B%9E%E5%BF%86%E4%B9%8B%E5%89%8D%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E6%88%91%E4%BB%AC%E7%94%A8%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E8%A1%A1%E9%87%8F%E9%82%A3%E5%A6%82%E6%9E%9C%E5%AF%B9%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%88%91%E4%BB%AC%E9%A2%84%E6%B5%8B%E7%9A%84%E7%BB%93%E6%9E%9C%E4%B8%8D%E5%AF%B9%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8E%BB%E8%A1%A1%E9%87%8F%E8%BF%99%E4%B8%AA%E6%8D%9F%E5%A4%B1%E5%91%A2%E6%88%91%E4%BB%AC%E6%9D%A5%E7%9C%8B%E8%BF%99%E6%A0%B7%E4%B8%80%E5%BC%A0%E5%9B%BE"><span class="toc-number">1.2.2.</span> <span class="toc-text">所以接下来我们回忆之前的线性回归预测结果我们用均方误差衡量，那如果对于逻辑回归，我们预测的结果不对该怎么去衡量这个损失呢？我们来看这样一张图</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">损失以及优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1"><span class="toc-number">2.1.</span> <span class="toc-text">损失</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">2.2.</span> <span class="toc-text">优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92api"><span class="toc-number">3.</span> <span class="toc-text">逻辑回归 API</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#logisticregression%E6%96%B9%E6%B3%95%E7%9B%B8%E5%BD%93%E4%BA%8E-sgdclassifierlosslog-penalty-sgdclassifier%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AD%A6%E4%B9%A0%E4%B9%9F%E6%94%AF%E6%8C%81%E5%B9%B3%E5%9D%87%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95asgd%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E8%AE%BE%E7%BD%AEaveragetrue-%E8%80%8C%E4%BD%BF%E7%94%A8logisticregression%E5%AE%9E%E7%8E%B0%E4%BA%86sag"><span class="toc-number">3.0.1.</span> <span class="toc-text">LogisticRegression 方法相当于 SGDClassifier (loss&#x3D;&quot;log&quot;, penalty&#x3D;&quot; &quot;),SGDClassifier 实现了一个普通的随机梯度下降学习，也支持平均随机梯度下降法（ASGD），可以通过设置 average&#x3D;True。而使用 LogisticRegression (实现了 SAG)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E7%99%8C%E7%97%87%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B-%E8%89%AF%E6%81%B6%E6%80%A7%E4%B9%B3%E8%85%BA%E7%99%8C%E8%82%BF%E7%98%A4%E9%A2%84%E6%B5%8B"><span class="toc-number">4.</span> <span class="toc-text">案例：癌症分类预测 - 良／恶性乳腺癌肿瘤预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90-4"><span class="toc-number">5.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-5"><span class="toc-number">6.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">7.</span> <span class="toc-text">分类的评估方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B2%BE%E7%A1%AE%E7%8E%87%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87"><span class="toc-number">7.1.</span> <span class="toc-text">精确率与召回率</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-number">7.1.1.</span> <span class="toc-text">混淆矩阵</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%B2%BE%E7%A1%AE%E7%8E%87precision%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87recall"><span class="toc-number">7.1.2.</span> <span class="toc-text">精确率 (Precision) 与召回率 (Recall)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E8%AF%84%E4%BC%B0%E6%8A%A5%E5%91%8Aapi"><span class="toc-number">7.1.3.</span> <span class="toc-text">分类评估报告 API</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E4%B8%8B%E7%9A%84%E8%AF%84%E4%BC%B0"><span class="toc-number">7.2.</span> <span class="toc-text">问题：如何衡量样本不均衡下的评估？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#roc%E6%9B%B2%E7%BA%BF%E4%B8%8Eauc%E6%8C%87%E6%A0%87"><span class="toc-number">7.3.</span> <span class="toc-text">ROC 曲线与 AUC 指标</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9F%A5%E9%81%93tpr%E4%B8%8Efpr"><span class="toc-number">7.3.1.</span> <span class="toc-text">知道 TPR 与 FPR</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#roc%E6%9B%B2%E7%BA%BF"><span class="toc-number">7.3.2.</span> <span class="toc-text">ROC 曲线</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#auc%E6%8C%87%E6%A0%87"><span class="toc-number">7.3.3.</span> <span class="toc-text">AUC 指标</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#auc%E8%AE%A1%E7%AE%97api"><span class="toc-number">7.3.4.</span> <span class="toc-text">AUC 计算 API</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">7.3.5.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-number"></span> <span class="toc-text">模型保存和加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-sklearn%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BDapi"><span class="toc-number">1.</span> <span class="toc-text">1、sklearn 模型的保存和加载 API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%8A%A0%E8%BD%BD%E6%A1%88%E4%BE%8B"><span class="toc-number">2.</span> <span class="toc-text">2、线性回归的模型保存加载案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-k-means%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">无监督学习 - K-means 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">1、 什么是无监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%8C%85%E5%90%AB%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">2、 无监督学习包含算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-k-means%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">3、 K-means 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#31-k-means%E8%81%9A%E7%B1%BB%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 K-means 聚类步骤</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-k-meansapi"><span class="toc-number">4.</span> <span class="toc-text">4、K-meansAPI</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%A1%88%E4%BE%8Bk-means%E5%AF%B9instacart-market%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB"><span class="toc-number">5.</span> <span class="toc-text">5、 案例：k-means 对 Instacart Market 用户聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#51-%E5%88%86%E6%9E%90"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#52-%E4%BB%A3%E7%A0%81"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E5%8E%BB%E8%AF%84%E4%BC%B0%E8%81%9A%E7%B1%BB%E7%9A%84%E6%95%88%E6%9E%9C%E5%91%A2"><span class="toc-number">5.3.</span> <span class="toc-text">问题：如何去评估聚类的效果呢？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-kmeans%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">6.</span> <span class="toc-text">6、Kmeans 性能评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#61-%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0"><span class="toc-number">6.1.</span> <span class="toc-text">6.1 轮廓系数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#62-%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90"><span class="toc-number">6.2.</span> <span class="toc-text">6.2 轮廓系数值分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#63-%E7%BB%93%E8%AE%BA"><span class="toc-number">6.3.</span> <span class="toc-text">6.3 结论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#64-%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0api"><span class="toc-number">6.4.</span> <span class="toc-text">6.4 轮廓系数 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#65-%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BC%B0"><span class="toc-number">6.5.</span> <span class="toc-text">6.5 用户聚类结果评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-k-means%E6%80%BB%E7%BB%93"><span class="toc-number">7.</span> <span class="toc-text">7、K-means 总结</span></a></li></ol></li></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" rel="bookmark" title="机器学习基础">机器学习基础</a></li><li><a href="/2022/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/" rel="bookmark" title="机器学习资料">机器学习资料</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="lzs" data-src="/images/avatar.jpg"><p class="name" itemprop="name">lzs</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">31</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">12</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">35</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3plbmdzaGVuZ2xpNzc1" title="https:&#x2F;&#x2F;github.com&#x2F;zengshengli775"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9senMtNDg=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;lzs-48"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE4ODAwNzc0NjY=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1880077466"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9naXRlZS5jb20vemVuZ3NoZW5nbGk3NzUvemVuZ3NoZW5nbGk3NzU=" title="https:&#x2F;&#x2F;gitee.com&#x2F;zengshengli775&#x2F;zengshengli775"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2021/08/25/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/Mac%20VScode%E5%BF%AB%E6%8D%B7%E9%94%AE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2021/08/26/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/PS4%E4%BB%A3%E7%90%86%E4%B8%8A%E7%BD%91/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/" title="分类于 实用技巧">实用技巧</a></div><span><a href="/2021/09/01/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7/" title="在线工具">在线工具</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2021/09/28/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/C%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="C语言基础知识">C语言基础知识</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="分类于 机器学习">机器学习</a></div><span><a href="/2022/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/" title="机器学习资料">机器学习资料</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" title="分类于 学习工具">学习工具</a></div><span><a href="/2022/02/18/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E7%BD%91%E7%AB%99/" title="学习资料网站">学习资料网站</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2021/08/27/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/C++%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="C++基础知识">C++基础知识</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" title="分类于 学习工具">学习工具</a></div><span><a href="/2021/09/22/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/%E4%B8%AD%E6%96%87PDF%E7%94%B5%E5%AD%90%E4%B9%A6%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E4%B9%A6%E7%AD%BE/" title="中文PDF电子书自动添加书签">中文PDF电子书自动添加书签</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%9C%9F%E6%9C%AB/" title="分类于 期末">期末</a></div><span><a href="/2021/08/11/%E6%9C%9F%E6%9C%AB/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E8%B5%84%E6%96%99/" title="期末复习资料">期末复习资料</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2022/02/18/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/%E5%AD%A6%E4%B9%A0C%E5%92%8CC++%E7%A2%B0%E5%88%B0%E7%9A%84%E7%9A%84%E7%96%91%E9%9A%BE%E7%82%B9/" title="学习C和C++碰到的的疑难点">学习C和C++碰到的的疑难点</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%8D%9A%E5%AE%A2/" title="分类于 博客">博客</a></div><span><a href="/2021/08/11/%E5%8D%9A%E5%AE%A2/%E8%BD%AC%E8%BD%BD%E5%8D%9A%E5%AE%A2%E6%96%B9%E6%B3%95/" title="转载博客方法">转载博客方法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%80%83%E7%A0%94/" title="分类于 考研">考研</a></div><span><a href="/2021/08/10/%E8%80%83%E7%A0%94/%E8%80%83%E7%A0%94%E8%B5%84%E6%96%99%E7%BD%91%E7%AB%99%E6%B1%87%E6%80%BB/" title="考研资料网站汇总">考研资料网站汇总</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">lzs @ Sakura</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">291k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">4:24</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2021/08/26/机器学习/机器学习基础/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->