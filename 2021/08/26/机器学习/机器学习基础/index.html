<!-- build time:Sat Oct 02 2021 14:22:04 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><meta name="referrer" content="no-referrer"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Sakura" href="https://zengshengli775.gitee.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Sakura" href="https://zengshengli775.gitee.io/atom.xml"><link rel="alternate" type="application/json" title="Sakura" href="https://zengshengli775.gitee.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="机器学习"><link rel="canonical" href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><title>机器学习基础 - 机器学习 | Sakura = Sakura = 我以为18岁之后是19岁，19岁之后是18岁，20岁永远都不会到来 。</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">机器学习基础</h1><div class="meta"><span class="item" title="创建时间：2021-08-26 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-08-26T00:00:00+08:00">2021-08-26</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>17k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>15 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Sakura</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="http://www.dmoe.cc/random.php?55152"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?610995"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?335451"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?710798"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?77155"></li><li class="item" data-background-image="http://www.dmoe.cc/random.php?45437"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="lzs"><meta itemprop="description" content="我以为18岁之后是19岁，19岁之后是18岁，20岁永远都不会到来 。, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Sakura"></span><div class="body md" itemprop="articleBody"><h3 id="李宏毅机器学习笔记"><a class="anchor" href="#李宏毅机器学习笔记">#</a> <span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlbWwtbm90ZXMvIy8=">李宏毅机器学习笔记</span></h3><h3 id="黑马程序员3天快速入门python机器学习"><a class="anchor" href="#黑马程序员3天快速入门python机器学习">#</a> <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMW50NDExcjd0ag==">黑马程序员 3 天快速入门 python 机器学习</span></h3><h3 id="黑马-3天快速入门-python机器学习-html"><a class="anchor" href="#黑马-3天快速入门-python机器学习-html">#</a> <span class="exturl" data-url="aHR0cHM6Ly9lbWFpbG5jdWVkdWNuLW15LnNoYXJlcG9pbnQuY29tLzpmOi9nL3BlcnNvbmFsLzYxMDgxMTkwOTRfZW1haWxfbmN1X2VkdV9jbi9Fc0tseHBxRmhYSkRtNElVMFJiYld6MEJ6WFFqb2ZvZUNKOTZXTEpKQThmUm1BP2U9bjFTaDV1">[黑马] 3 天快速入门 python 机器学习 - html</span></h3><h2 id="1机器学习概述"><a class="anchor" href="#1机器学习概述">#</a> 1. 机器学习概述</h2><h3 id="11什么是机器学习"><a class="anchor" href="#11什么是机器学习">#</a> 1.1 什么是机器学习</h3><p>机器学习是从<strong>数据</strong>中<strong>自动分析获得模型</strong>，并利用<strong>模型</strong>对未知数据进行预测。</p><p>数据集构成：特征值 + 目标值</p><h3 id="12机器学习算法分类"><a class="anchor" href="#12机器学习算法分类">#</a> 1.2 机器学习算法分类</h3><ul><li>监督学习 (supervised learning)（预测）<ul><li>定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值 (称为回归），或是输出是有限个离散值（称作分类）。</li><li><strong>分类 k - 近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络</strong></li><li><strong>回归 线性回归、岭回归</strong></li></ul></li><li>无监督学习 (unsupervised learning)<ul><li>定义：输入数据是由输入特征值所组成。</li><li><strong>聚类 k-means</strong></li></ul></li></ul><h3 id="13开发流程"><a class="anchor" href="#13开发流程">#</a> 1.3 开发流程</h3><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532152.jpg" alt="开发流程.png"></p><h2 id="2特征工程"><a class="anchor" href="#2特征工程">#</a> 2. 特征工程</h2><h3 id="21数据集"><a class="anchor" href="#21数据集">#</a> 2.1 数据集</h3><h4 id="211-可用数据集"><a class="anchor" href="#211-可用数据集">#</a> 2.1.1 可用数据集</h4><p>​ Kaggle 网址：<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9kYXRhc2V0cw==">https://www.kaggle.com/datasets</span></p><p>​ UCI 数据集网址： <span class="exturl" data-url="aHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwv">http://archive.ics.uci.edu/ml/</span></p><p>​ scikit-learn 网址：<span class="exturl" data-url="aHR0cDovL3NjaWtpdC1sZWFybi5vcmcvc3RhYmxlL2RhdGFzZXRzL2luZGV4Lmh0bWw=">http://scikit-learn.org/stable/datasets/index.html#datasets</span></p><h4 id="212-sklearn"><a class="anchor" href="#212-sklearn">#</a> 2.1.2 sklearn</h4><ul><li>sklearn.datasets 加载获取流行数据集<ul><li>datasets.load_*()	获取小规模数据集，数据包含在 datasets 里</li><li>datasets.fetch_*(data_home=None)	获取大规模数据集，需要从网络上下载，函数的第一个参数是 data_home，表示数据集下载的目录，默认是～/scikit_learn_data/</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 获取鸢尾花数据集</span></pre></td></tr><tr><td data-num="3"></td><td><pre>iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花数据集的返回值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 返回值是一个继承自字典的 Bench</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的特征值:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的目标值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花特征的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花目标值的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的描述：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>DESCR<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="22-特征工程介绍"><a class="anchor" href="#22-特征工程介绍">#</a> 2.2 特征工程介绍</h3><p>​	特征工程是使用<strong>专业背景知识和技巧处理数据</strong>，<strong>使得特征能在机器学习算法上发挥更好的作用的过程</strong>。</p><p><strong>特征工程包含内容</strong></p><ul><li>特征抽取</li><li>特征预处理</li><li>特征降维</li></ul><h3 id="23-特征抽取"><a class="anchor" href="#23-特征抽取">#</a> 2.3 特征抽取</h3><p>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</p><ul><li>字典特征提取 (特征离散化)</li><li>文本特征提取</li><li>图像特征提取（深度学习将介绍）</li></ul><h4 id="232-字典特征提取"><a class="anchor" href="#232-字典特征提取">#</a> 2.3.2 字典特征提取</h4><p><strong>作用：对字典数据进行特征值化</strong></p><p><strong>对于特征当中存在类别信息的我们都会做 one-hot 编码处理</strong></p><ul><li>sklearn.feature_extraction.DictVectorizer(sparse=True,…)<ul><li>DictVectorizer.fit_transform (X) X: 字典或者包含字典的迭代器返回值：返回 sparse 矩阵</li><li>DictVectorizer.inverse_transform (X) X:array 数组或者 sparse 矩阵 返回值：转换之前数据格式</li><li>DictVectorizer.get_feature_names () 返回类别名称</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">dict_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对字典类型的数据进行特征抽取</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment">#sparse=False 参数，one-hot 编码处理</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回的结果:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment"># 打印特征名字</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="233-文本特征提取"><a class="anchor" href="#233-文本特征提取">#</a> 2.3.3 文本特征提取</h4><p><strong>作用：对文本数据进行特征值化</strong></p><h5 id="2331sklearnfeature_extractiontextcountvectorizerstop_words返回词频矩阵统计每个样本特征词出现的个数"><a class="anchor" href="#2331sklearnfeature_extractiontextcountvectorizerstop_words返回词频矩阵统计每个样本特征词出现的个数">#</a> 2.3.3.1.<strong>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</strong>	<strong>返回词频矩阵，统计每个样本特征词出现的个数</strong>。</h5><ul><li><p>CountVectorizer.fit_transform (X) X: 文本或者包含文本字符串的可迭代对象 返回值：返回 sparse 矩阵</p></li><li><p>CountVectorizer.inverse_transform (X) X:array 数组或者 sparse 矩阵 返回值：转换之前数据格</p></li><li><p>CountVectorizer.get_feature_names () 返回值：单词列表</p><h6 id="23311对英文进行特征提取"><a class="anchor" href="#23311对英文进行特征提取">#</a> 2.3.3.1.1<strong> 对英文进行特征提取</strong></h6></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对文本进行特征抽取，countvetorizer</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"life is short,i like like python"</span><span class="token punctuation">,</span> <span class="token string">"life is too long,i dislike python"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment">#调用 fit_transform 方法输入数据并转换 （注意返回格式，</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h6 id="23312对中文进行特征提取"><a class="anchor" href="#23312对中文进行特征提取">#</a> 2.3.3.1.2<strong> 对中文进行特征提取</strong></h6><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    对中文进行分词</pre></td></tr><tr><td data-num="7"></td><td><pre>    "我爱北京天安门"————>"我 爱 北京 天安门"</pre></td></tr><tr><td data-num="8"></td><td><pre>    :param text:</pre></td></tr><tr><td data-num="9"></td><td><pre>    :return: text</pre></td></tr><tr><td data-num="10"></td><td><pre>    """</pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 用结巴对中文字符串进行分词</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    text <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">return</span> text</pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_chinese_count_demo2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    对中文进行特征抽取</pre></td></tr><tr><td data-num="19"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="20"></td><td><pre>    """</pre></td></tr><tr><td data-num="21"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            <span class="token string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            <span class="token string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment"># 将原始数据转换成分好词的形式</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h5 id="2332sklearnfeature_extractiontexttfidfvectorizer用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度"><a class="anchor" href="#2332sklearnfeature_extractiontexttfidfvectorizer用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度">#</a> 2.3.3.2.<strong>sklearn.feature_extraction.text.TfidfVectorizer</strong>	<strong>用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</strong></h5><ul><li>词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率</li><li>逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的 idf，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取以 10 为底的对数得到</strong></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532964.jpg" alt="tfidf公式.png"></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> jieba</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    对中文进行分词</pre></td></tr><tr><td data-num="7"></td><td><pre>    "我爱北京天安门"————>"我 爱 北京 天安门"</pre></td></tr><tr><td data-num="8"></td><td><pre>    :param text:</pre></td></tr><tr><td data-num="9"></td><td><pre>    :return: text</pre></td></tr><tr><td data-num="10"></td><td><pre>    """</pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 用结巴对中文字符串进行分词</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    text <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">return</span> text</pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">def</span> <span class="token function">text_chinese_tfidf_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    对中文进行特征抽取</pre></td></tr><tr><td data-num="19"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="20"></td><td><pre>    """</pre></td></tr><tr><td data-num="21"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            <span class="token string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            <span class="token string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment"># 将原始数据转换成分好词的形式</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># transfer = CountVectorizer(sparse=False)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"文本特征抽取的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"返回特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="24-特征预处理"><a class="anchor" href="#24-特征预处理">#</a> 2.4 特征预处理</h3><p>通过<strong>一些转换函数</strong>将特征数据<strong>转换成更加适合算法模型</strong>的特征数据过程</p><ul><li>数值型数据的无量纲化：<ul><li>归一化</li><li>标准化</li></ul></li></ul><h4 id="241归一化"><a class="anchor" href="#241归一化">#</a> 2.4.1 归一化</h4><p>通过对原始数据进行变换把数据映射到 (默认为 [0,1]) 之间</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011532546.jpg" alt="image.png"></p><blockquote><p>作用于每一列，max 为一列的最大值，min 为一列的最小值，那么 X’’为最终结果，mx，mi 分别为指定区间值默认 mx 为 1,mi 为 0</p></blockquote><ul><li>sklearn.preprocessing.MinMaxScaler (feature_range=(0,1)… )<ul><li>MinMaxScalar.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li></ul></li><li>返回值：转换后的形状相同的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">minmax_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    归一化演示</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    transfer <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'milage'</span><span class="token punctuation">,</span><span class="token string">'Liters'</span><span class="token punctuation">,</span><span class="token string">'Consumtime'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最小值最大值归一化处理的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p><strong>归一化鲁棒性较差，只适合传统精确小数据场景。</strong></p><h4 id="242标准化"><a class="anchor" href="#242标准化">#</a> 2.4.2 标准化</h4><p>通过对原始数据进行变换把数据变换到均值为 0, 标准差为 1 范围内</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533098.jpg" alt="image.png"></p><p>作用于每一列，mean 为平均值，σ 为标准差</p><ul><li>sklearn.preprocessing.StandardScaler( )<ul><li>处理之后每列来说所有数据都聚集在均值 0 附近标准差差为 1</li><li>StandardScaler.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li></ul></li><li>返回值：转换后的形状相同的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">stand_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    标准化演示</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    transfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'milage'</span><span class="token punctuation">,</span><span class="token string">'Liters'</span><span class="token punctuation">,</span><span class="token string">'Consumtime'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"标准化的结果:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每一列特征的平均值：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>mean_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每一列特征的方差：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>var_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p>在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。</p><h3 id="25-特征降维"><a class="anchor" href="#25-特征降维">#</a> 2.5 特征降维</h3><h4 id="251-降维"><a class="anchor" href="#251-降维">#</a> 2.5.1 降维</h4><p><strong>降维</strong>是指在某些限定条件下，<strong>降低随机变量 (特征) 个数</strong>，得到<strong>一组 “不相关” 主变量</strong>的过程</p><ul><li><strong>特征选择</strong></li><li><strong>主成分分析</strong></li></ul><h4 id="252特征选择"><a class="anchor" href="#252特征选择">#</a> 2.5.2 特征选择</h4><p>数据中包含<strong>冗余或无关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出主要特征</strong>。</p><h5 id="2521方法"><a class="anchor" href="#2521方法">#</a> 2.5.2.1 方法</h5><ul><li>Filter (过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联<ul><li><strong>方差选择法：低方差特征过滤</strong></li><li><strong>相关系数</strong></li></ul></li><li>Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul><li><strong>决策树：信息熵、信息增益</strong></li><li><strong>正则化：L1、L2</strong></li><li><strong>深度学习：卷积等</strong></li></ul></li></ul><h5 id="2522过滤式"><a class="anchor" href="#2522过滤式">#</a> 2.5.2.2 过滤式</h5><ul><li><p>特征方差小：某个特征大多样本的值比较相近</p></li><li><p>特征方差大：某个特征很多样本的值都有差别</p></li><li><p>sklearn.feature_selection.VarianceThreshold(threshold = 0.0)</p><ul><li>删除所有低方差特征</li><li>Variance.fit_transform(X)<ul><li>X:numpy array 格式的数据 [n_samples,n_features]</li><li>返回值：训练集差异低于 threshold 的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。</li></ul></li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">variance_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    删除低方差特征——特征选择</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"factor_returns.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token comment"># 1、实例化一个转换器类</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    transfer <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"删除低方差特征的结果：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"形状：\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="253相关系数"><a class="anchor" href="#253相关系数">#</a> 2.5.3 相关系数</h4><p><strong>相关系数的值介于–1 与 + 1 之间，即–1≤ r ≤+1</strong>。其性质如下：</p><ul><li><strong>当 r&gt;0 时，表示两变量正相关，r&lt;0 时，两变量为负相关</strong></li><li>当 | r|=1 时，表示两变量为完全相关，当 r=0 时，表示两变量间无相关关系</li><li><strong>当 0&lt;|r|&lt;1 时，表示两变量存在一定程度的相关。且 | r | 越接近 1，两变量间线性关系越密切；|r | 越接近于 0，表示两变量的线性相关越弱</strong></li><li><strong>一般可按三级划分：|r|&lt;0.4 为低度相关；0.4≤|r|&lt;0.7 为显著性相关；0.7≤|r|&lt;1 为高度线性相关</strong></li></ul><blockquote><p>这个符号：|r | 为 r 的绝对值， |-5| = 5</p></blockquote><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533904.jpg" alt="image.png"></p><ul><li>from scipy.stats import pearsonr<ul><li>x : (N,) array_like</li><li>y : (N,) array_like Returns: (Pearson’s correlation coefficient, p-value)</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">def</span> <span class="token function">pearsonr_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    相关系数计算</pre></td></tr><tr><td data-num="7"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="8"></td><td><pre>    """</pre></td></tr><tr><td data-num="9"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"factor_returns.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    factor <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'pe_ratio'</span><span class="token punctuation">,</span> <span class="token string">'pb_ratio'</span><span class="token punctuation">,</span> <span class="token string">'market_cap'</span><span class="token punctuation">,</span> <span class="token string">'return_on_asset_net_profit'</span><span class="token punctuation">,</span> <span class="token string">'du_return_on_equity'</span><span class="token punctuation">,</span> <span class="token string">'ev'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>              <span class="token string">'earnings_per_share'</span><span class="token punctuation">,</span> <span class="token string">'revenue'</span><span class="token punctuation">,</span> <span class="token string">'total_expense'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>factor<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>factor<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="17"></td><td><pre>                <span class="token string">"指标%s与指标%s之间的相关性大小为%f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>factor<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> factor<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span>factor<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span>factor<span class="token punctuation">[</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="26主成分分析pca"><a class="anchor" href="#26主成分分析pca">#</a> 2.6 主成分分析 (PCA)</h3><ul><li><p>定义：<strong>高维数据转化为低维数据的过程</strong>，在此过程中<strong>可能会舍弃原有数据、创造新的变量</strong></p></li><li><p>作用：<strong>是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。</strong></p></li><li><p>应用：回归分析或者聚类分析当中</p></li><li><p>sklearn.decomposition.PCA(n_components=None)</p><ul><li>将数据分解为较低维数空间</li><li>n_components:<ul><li><strong>小数：表示保留百分之多少的信息</strong></li><li><strong>整数：减少到多少特征</strong></li></ul></li><li>PCA.fit_transform (X) X:numpy array 格式的数据 [n_samples,n_features]</li><li>返回值：转换后指定维度的 array</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">def</span> <span class="token function">pca_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    对数据进行PCA降维</pre></td></tr><tr><td data-num="6"></td><td><pre>    :return: None</pre></td></tr><tr><td data-num="7"></td><td><pre>    """</pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 1、实例化 PCA, 小数 —— 保留多少信息</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    transfer <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    data1 <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"保留90%的信息，降维结果为：\n"</span><span class="token punctuation">,</span> data1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token comment"># 1、实例化 PCA, 整数 —— 指定降维到的维数</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    transfer2 <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment"># 2、调用 fit_transform</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    data2 <span class="token operator">=</span> transfer2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"降维到3维的结果：\n"</span><span class="token punctuation">,</span> data2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533446.jpg" alt="image.png"></p><h2 id="3分类算法"><a class="anchor" href="#3分类算法">#</a> 3. 分类算法</h2><h3 id="31数据集介绍与划分"><a class="anchor" href="#31数据集介绍与划分">#</a> 3.1 数据集介绍与划分</h3><h4 id="数据集的划分"><a class="anchor" href="#数据集的划分">#</a> 数据集的划分</h4><p>机器学习一般的数据集会划分为两个部分：</p><ul><li>训练数据：用于训练，构建模型</li><li>测试数据：在模型检验时使用，用于评估模型是否有效</li></ul><p>划分比例：</p><ul><li>训练集：70% 80% 75%</li><li>测试集：30% 20% 30%</li></ul><h4 id="api"><a class="anchor" href="#api">#</a> API</h4><ul><li><p>sklearn.model_selection.train_test_split(</p><p>arrays, *</p><p>options)</p><ul><li>x 数据集的特征值</li><li>y 数据集的标签值</li><li>test_size 测试集的大小，一般为 float</li><li>random_state 随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。</li><li>return ，测试集特征训练集特征值值，训练标签，测试标签 (默认随机取)</li></ul></li></ul><h4 id="sklearn数据集介绍"><a class="anchor" href="#sklearn数据集介绍">#</a> sklearn 数据集介绍</h4><h4 id="api-2"><a class="anchor" href="#api-2">#</a> API</h4><ul><li>sklearn.datasets<ul><li>加载获取流行数据集</li><li>datasets.load_*()<ul><li>获取小规模数据集，数据包含在 datasets 里</li></ul></li><li>datasets.fetch_*(data_home=None)<ul><li>获取大规模数据集，需要从网络上下载，函数的第一个参数是 data_home，表示数据集下载的目录，默认是～/scikit_learn_data/</li></ul></li></ul></li></ul><h4 id="分类和回归数据集"><a class="anchor" href="#分类和回归数据集">#</a> 分类和回归数据集</h4><ul><li>分类数据集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533830.jpg" alt="image.png"></p><ul><li>sklearn.datasets.fetch_20newsgroups(data_home=None,subset=‘train’)<ul><li>subset: 'train' 或者 'test','all'，可选，选择要加载的数据集。训练集的 “训练”，测试集的 “测试”，两者的 “全部”</li></ul></li><li>回归数据集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011533845.jpg" alt="image.png"></p><h4 id="返回类型"><a class="anchor" href="#返回类型">#</a> 返回类型</h4><ul><li><p>load</p><p>和 fetch</p><p>返回的数据类型 datasets.base.Bunch (字典格式)</p><ul><li>data：特征数据数组，是 [n_samples * n_features] 的二维 numpy.ndarray 数组</li><li>target：标签数组，是 n_samples 的一维 numpy.ndarray 数组</li><li>DESCR：数据描述</li><li>feature_names：特征名，新闻数据，手写数字、回归数据集没有</li><li>target_names：标签名</li></ul></li></ul><h3 id="32sklearn转换器和估计器"><a class="anchor" href="#32sklearn转换器和估计器">#</a> 3.2sklearn 转换器和估计器</h3><h4 id="1转换器"><a class="anchor" href="#1转换器">#</a> 1. 转换器</h4><p>特征工程的步骤:</p><ul><li>1、实例化 (实例化的是一个转换器类 (Transformer))</li><li>2、调用 fit_transform (对于文档建立分类词频矩阵，不能同时调用)</li></ul><p>我们把特征工程的接口称之为转换器，其中转换器调用有这么几种形式</p><ul><li>fit_transform</li><li>fit</li><li>transform</li></ul><p><strong>这几个方法之间的区别:</strong></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std1 <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std1<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2 <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">:</span> StandardScaler<span class="token punctuation">(</span>copy<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> with_mean<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> with_std<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>从中可以看出，fit_transform 的作用相当于 transform 加上 fit。但是为什么还要提供单独的 fit 呢，我们还是使用原来的 std2 来进行标准化看看</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>       <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> std2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>Out<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="2估计器sklearn机器学习算法的实现"><a class="anchor" href="#2估计器sklearn机器学习算法的实现">#</a> 2. 估计器 (sklearn 机器学习算法的实现)</h4><p>在 sklearn 中，估计器 (estimator) 是一个重要的角色，是一类实现了算法的 API</p><ul><li>1、用于分类的估计器：<ul><li>sklearn.neighbors k - 近邻算法</li><li>sklearn.naive_bayes 贝叶斯</li><li>sklearn.linear_model.LogisticRegression 逻辑回归</li><li>sklearn.tree 决策树与随机森林</li></ul></li><li>2、用于回归的估计器：<ul><li>sklearn.linear_model.LinearRegression 线性回归</li><li>sklearn.linear_model.Ridge 岭回归</li></ul></li><li>3、用于无监督学习的估计器<ul><li>sklearn.cluster.KMeans 聚类</li></ul></li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534346.jpg" alt="image.png"></p><h3 id="33-k-近邻算法knn"><a class="anchor" href="#33-k-近邻算法knn">#</a> 3.3 K - 近邻算法 (KNN)</h3><h4 id="定义"><a class="anchor" href="#定义">#</a> 定义</h4><p>如果一个样本在特征空间中的<strong> k 个最相似 (即特征空间中最邻近) 的样本中的大多数属于某一个类别</strong>，则该样本也属于这个类别。</p><blockquote><p>来源：KNN 算法最早是由 Cover 和 Hart 提出的一种分类算法</p></blockquote><h4 id="距离公式"><a class="anchor" href="#距离公式">#</a> 距离公式</h4><p>两个样本的距离可以通过如下公式计算，又叫欧式距离</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534200.jpg" alt="image.png"></p><h4 id="k-近邻算法api"><a class="anchor" href="#k-近邻算法api">#</a> K - 近邻算法 API</h4><ul><li>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm='auto')<ul><li>n_neighbors：int, 可选（默认 = 5），k_neighbors 查询默认使用的邻居数</li><li>algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给 fit 方法的值来决定最合适的算法。 (不同实现方式影响效率)</li></ul></li></ul><h4 id="预测签到位置"><a class="anchor" href="#预测签到位置">#</a> 预测签到位置</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534376.jpg" alt="image.png"></p><p>数据介绍：将根据用户的位置，准确性和时间戳预测用户正在查看的业务。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train<span class="token punctuation">.</span>csv，test<span class="token punctuation">.</span>csv </pre></td></tr><tr><td data-num="2"></td><td><pre>row_id：登记事件的ID</pre></td></tr><tr><td data-num="3"></td><td><pre>xy：坐标</pre></td></tr><tr><td data-num="4"></td><td><pre>准确性：定位准确性 </pre></td></tr><tr><td data-num="5"></td><td><pre>时间：时间戳</pre></td></tr><tr><td data-num="6"></td><td><pre>place_id：业务的ID，这是您预测的目标</pre></td></tr></table></figure><blockquote><p>官网：<span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9uYXZvc2h0YS9ncmlkLWtubi9kYXRh">https://www.kaggle.com/navoshta/grid-knn/data</span></p></blockquote><h4 id="分析"><a class="anchor" href="#分析">#</a> 分析</h4><ul><li><p>对于数据做一些基本处理（这里所做的一些处理不一定达到很好的效果，我们只是简单尝试，有些特征我们可以根据一些特征选择的方式去做处理）</p><ul><li><p>1、缩小数据集范围 DataFrame.query ()</p></li><li><p>4、删除没用的日期数据 DataFrame.drop（可以选择保留）</p></li><li><p>5、将签到位置少于 n 个用户的删除</p><p>place_count = data.groupby('place_id').count()</p><p>tf = place_count[place_count.row_id &gt; 3].reset_index()</p><p>data = data[data['place_id'].isin(tf.place_id)]</p></li></ul></li><li><p>分割数据集</p></li><li><p>标准化处理</p></li><li><p>k - 近邻预测</p></li></ul><h4 id="代码"><a class="anchor" href="#代码">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">knncls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    K近邻算法预测入住位置类别</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 一、处理数据以及特征工程</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment"># 1、读取收，缩小数据的范围</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/FBlocation/train.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># 数据逻辑筛选操作 df.query ()</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"x > 1.0 &amp; x &lt; 1.25 &amp; y > 2.5 &amp; y &lt; 2.75"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 删除 time 这一列特征</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># 删除入住次数少于三次位置</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    place_count <span class="token operator">=</span> data<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'place_id'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    tf <span class="token operator">=</span> place_count<span class="token punctuation">[</span>place_count<span class="token punctuation">.</span>row_id <span class="token operator">></span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    data <span class="token operator">=</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>place_id<span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token comment"># 3、取出特征值和目标值</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment"># y = data[['place_id']]</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    x <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">,</span> <span class="token string">'row_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># 4、数据分割与特征工程？</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment"># （1）、数据分割</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token comment"># (2)、标准化</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    std <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token comment"># 队训练集进行标准化操作</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    x_train <span class="token operator">=</span> std<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token comment"># 进行测试集的标准化操作</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    x_test <span class="token operator">=</span> std<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token comment"># 二、算法的输入训练预测</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token comment"># K 值：算法传入参数不定的值    理论上：k = 根号 (样本数)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token comment"># K 值：后面会使用参数调优方法，去轮流试出最好的参数 [1,3,5,10,20,100,200]</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token comment"># 调用 fit ()</span></pre></td></tr><tr><td data-num="52"></td><td><pre>    knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token comment"># 预测测试数据集，得出准确率</span></pre></td></tr><tr><td data-num="55"></td><td><pre>    y_predict <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测测试集类别："</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"准确率为："</span><span class="token punctuation">,</span> knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre></pre></td></tr><tr><td data-num="61"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="34模型选择与调优"><a class="anchor" href="#34模型选择与调优">#</a> 3.4 模型选择与调优</h3><p>交叉验证目的：<strong>为了让被评估的模型更加准确可信</strong></p><p>交叉验证：将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成 5 份，其中一份作为验证集。然后经过 5 次 (组) 的测试，每次都更换不同的验证集。即得到 5 组模型的结果，取平均值作为最终结果。又称 5 折交叉验证。</p><ul><li>训练集：训练集 + 验证集</li><li>测试集：测试集</li></ul><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534706.jpg" alt="image.png"></p><h4 id="超参数搜索-网格搜索grid-search"><a class="anchor" href="#超参数搜索-网格搜索grid-search">#</a> 超参数搜索 - 网格搜索 (Grid Search)</h4><p>通常情况下，<strong>有很多参数是需要手动指定的（如 k - 近邻算法中的 K 值），这种叫超参数</strong>。但是手动过程繁杂，所以需要对模型预设几种超参数组合。<strong>每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</strong></p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534438.jpg" alt="image.png"></p><h4 id="模型选择与调优"><a class="anchor" href="#模型选择与调优">#</a> 模型选择与调优</h4><ul><li>sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)<ul><li>对估计器的指定参数值进行详尽搜索</li><li>estimator：估计器对象</li><li “n_neighbors”:[1,3,5]="">param_grid：估计器参数 (dict)</li><li>cv：指定几折交叉验证</li><li></li><li>fit：输入训练数据</li><li>score：准确率</li><li>结果分析：<ul><li>best<em>score</em>: 在交叉验证中验证的最好结果_</li><li>best<em>estimator</em>：最好的参数模型</li><li>cv<em>results</em>: 每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul></li></ul></li></ul><h4 id="facebook签到位置预测k值调优"><a class="anchor" href="#facebook签到位置预测k值调优">#</a> Facebook 签到位置预测 K 值调优</h4><ul><li>使用网格搜索估计器</li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 使用网格搜索和交叉验证找到合适的参数</span></pre></td></tr><tr><td data-num="2"></td><td><pre>knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>param <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>gc <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>gc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"选择了某个模型测试集当中预测的准确率为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 训练验证集的结果</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"在交叉验证当中验证的最好结果："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gc选择了的模型K值是："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"每次交叉验证的结果为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="35朴素贝叶斯算法"><a class="anchor" href="#35朴素贝叶斯算法">#</a> 3.5 朴素贝叶斯算法</h3><blockquote><p>朴素贝叶斯算法 = 朴素 + 贝叶斯</p><p>朴素：变量与变量之间相互独立</p><p>贝叶斯：贝叶斯公式</p></blockquote><h4 id="条件概率与联合概率"><a class="anchor" href="#条件概率与联合概率">#</a> 条件概率与联合概率</h4><ul><li>联合概率：包含多个条件，且所有条件同时成立的概率<ul><li>记作：P (A,B)</li><li>特性：P (A, B) = P (A) P (B)</li></ul></li><li>条件概率：就是事件 A 在另外一个事件 B 已经发生条件下的发生概率<ul><li>记作：P (A|B)</li><li>特性：P (A1,A2|B) = P (A1|B) P (A2|B)</li></ul></li></ul><blockquote><p>注意：此条件概率的成立，<strong>是由于 A1,A2 相互独立的结果</strong> (记忆)</p></blockquote><h4 id="贝叶斯公式"><a class="anchor" href="#贝叶斯公式">#</a> 贝叶斯公式</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534795.jpg" alt="image.png"></p><p><strong>那么这个公式如果应用在文章分类的场景当中，我们可以这样看：</strong></p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534565.jpg" alt="image.png"></p><p>公式分为三个部分：</p><ul><li>P (C)：每个文档类别的概率 (某文档类别数／总文档数量)</li><li>P (W│C)：给定类别下特征（被预测文档中出现的词）的概率<ul><li>计算方法：P (F1│C)=Ni/N （训练文档中去计算）<ul><li>Ni 为该 F1 词在 C 类别所有文档中出现的次数</li><li>N 为所属类别 C 下的文档所有词出现的次数和</li></ul></li></ul></li><li>P (F1,F2,…) 预测文档中每个词的概率</li></ul><h4 id="拉普拉斯平滑系数"><a class="anchor" href="#拉普拉斯平滑系数">#</a> 拉普拉斯平滑系数</h4><p>目的：防止计算出的分类概率为 0</p><p><img data-src="http://tva1.sinaimg.cn/large/007QGucbgy1guz1kkl1hmj60ve05c3zu02.jpg" alt="image.png"></p><h4 id="api-3"><a class="anchor" href="#api-3">#</a> API</h4><ul><li>sklearn.naive_bayes.MultinomialNB(alpha = 1.0)<ul><li>朴素贝叶斯分类</li><li>alpha：拉普拉斯平滑系数</li></ul></li></ul><h4 id="20类新闻分类"><a class="anchor" href="#20类新闻分类">#</a> 20 类新闻分类</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011534818.jpg" alt="image.png"></p><h4 id="分析-2"><a class="anchor" href="#分析-2">#</a> 分析</h4><ul><li>分割数据集</li><li>tfidf 进行的特征抽取</li><li>朴素贝叶斯预测</li></ul><h4 id="代码-2"><a class="anchor" href="#代码-2">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">nbcls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    朴素贝叶斯对新闻数据集进行预测</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 获取新闻的数据，20 个类别</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    news <span class="token operator">=</span> fetch_20newsgroups<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">'all'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 进行数据集分割</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>news<span class="token punctuation">.</span>data<span class="token punctuation">,</span> news<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># 对于文本数据，进行特征抽取</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    tf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token comment"># 这里打印出来的列表是：训练集当中的所有不同词的组成的一个列表</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># print(x_train.toarray())</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token comment"># 不能调用 fit_transform</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token comment"># estimator 估计器流程</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    mlb <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>    mlb<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token comment"># 进行预测</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    y_predict <span class="token operator">=</span> mlb<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测每篇文章的类别："</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"真实类别为："</span><span class="token punctuation">,</span> y_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测准确率为："</span><span class="token punctuation">,</span> mlb<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="决策树"><a class="anchor" href="#决策树">#</a> 决策树</h3><h4 id="信息熵"><a class="anchor" href="#信息熵">#</a> 信息熵</h4><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011450474.png" alt="信息熵公式"></p><h4 id="信息增益-定义与公式"><a class="anchor" href="#信息增益-定义与公式">#</a> 信息增益 定义与公式</h4><p>特征 A 对训练数据集 D 的信息增益 g (D,A), 定义为集合 D 的信息熵 H (D) 与特征 A 给定条件下 D 的信息条件熵 H (D|A) 之差，即公式为：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011451005.png" alt="信息增益公式"></p><p>即公式为：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011452377.png" alt="信息增益公式"></p><p>公式的详细解释：</p><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011452988.png" alt="信息增益公式详解"></p><blockquote><p>注：信息增益表示得知特征 X 的信息而息的不确定性减少的程度使得类 Y 的信息熵减少的程度</p></blockquote><h4 id="决策树的三种算法实现"><a class="anchor" href="#决策树的三种算法实现">#</a> 决策树的三种算法实现</h4><p>当然决策树的原理不止信息增益这一种，还有其他方法。但是原理都类似，我们就不去举例计算。</p><ul><li>ID3<ul><li>信息增益 最大的准则</li></ul></li><li>C4.5<ul><li>信息增益比 最大的准则</li></ul></li><li>CART<ul><li>分类树：基尼系数 最小的准则 在 sklearn 中可以选择划分的默认原则</li><li>优势：划分更加细致（从后面例子的树显示来理解）</li></ul></li></ul><h4 id="决策树api"><a class="anchor" href="#决策树api">#</a> 决策树 API</h4><ul><li>class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)<ul><li>决策树分类器</li><li>criterion: 默认是’gini’系数，也可以选择信息增益的熵’entropy’</li><li>max_depth: 树的深度大小</li><li>random_state: 随机数种子</li></ul></li><li>其中会有些超参数：max_depth: 树的深度大小<ul><li>其它超参数我们会结合随机森林讲解</li></ul></li></ul><h4 id="泰坦尼克号乘客生存预测"><a class="anchor" href="#泰坦尼克号乘客生存预测">#</a> 泰坦尼克号乘客生存预测</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">decisioncls</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    决策树进行乘客生存预测</pre></td></tr><tr><td data-num="4"></td><td><pre>    :return:</pre></td></tr><tr><td data-num="5"></td><td><pre>    """</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment"># 1、获取数据</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    titan <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment"># 2、数据的处理</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    x <span class="token operator">=</span> titan<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    y <span class="token operator">=</span> titan<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token comment"># print(x , y)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment"># 缺失值需要处理，将特征当中有类别的这些特征进行字典特征抽取</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment"># 对于 x 转换成字典数据 x.to_dict (orient="records")</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment"># [&#123;"pclass": "1st", "age": 29.00, "sex": "female"&#125;, &#123;&#125;]</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token builtin">dict</span> <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    x <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">"records"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token comment"># 分割训练集合测试集</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment"># 进行决策树的建立和预测</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    dc <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    dc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测的准确率为："</span><span class="token punctuation">,</span> dc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">return</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h4 id="可视化决策树"><a class="anchor" href="#可视化决策树">#</a> 可视化决策树</h4><h4 id="保存树的结构到dot文件"><a class="anchor" href="#保存树的结构到dot文件">#</a> 保存树的结构到 dot 文件</h4><ul><li>1、sklearn.tree.export_graphviz () 该函数能够导出 DOT 格式<ul><li>tree.export_graphviz(estimator,out_file='tree.dot’,feature_names=[‘’,’’])</li></ul></li><li>2、工具：(能够将 dot 文件转换为 pdf、png)<ul><li>安装 graphviz</li><li>ubuntu:sudo apt-get install graphviz Mac:brew install graphviz</li></ul></li><li>3、运行命令<ul><li>然后我们运行这个命令</li><li>dot -Tpng tree.dot -o tree.png</li></ul></li></ul><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>export_graphviz<span class="token punctuation">(</span>dc<span class="token punctuation">,</span> out_file<span class="token operator">=</span><span class="token string">"./tree.dot"</span><span class="token punctuation">,</span> feature_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">,</span> <span class="token string">'pclass=1st'</span><span class="token punctuation">,</span> <span class="token string">'pclass=2nd'</span><span class="token punctuation">,</span> <span class="token string">'pclass=3rd'</span><span class="token punctuation">,</span> <span class="token string">'女性'</span><span class="token punctuation">,</span> <span class="token string">'男性'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="决策树总结"><a class="anchor" href="#决策树总结">#</a> 决策树总结</h4><ul><li>优点：<ul><li>简单的理解和解释，树木可视化。</li></ul></li><li>缺点：<ul><li><strong>决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。</strong></li></ul></li><li>改进：<ul><li>减枝 cart 算法 (决策树 API 当中已经实现，随机森林参数调优有相关介绍)</li><li><strong>随机森林</strong></li></ul></li></ul><h3 id="集成学习方法之随机森林"><a class="anchor" href="#集成学习方法之随机森林">#</a> 集成学习方法之随机森林</h3><h4 id="集成学习方法"><a class="anchor" href="#集成学习方法">#</a> 集成学习方法</h4><p>集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是<strong>生成多个分类器 / 模型</strong>，各自独立地学习和作出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。</strong></p><h4 id="随机森林"><a class="anchor" href="#随机森林">#</a> 随机森林</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定。</p><h4 id="随机森林原理过程"><a class="anchor" href="#随机森林原理过程">#</a> 随机森林原理过程</h4><p>学习算法根据下列算法而建造每棵树：</p><ul><li>用 N 来表示训练用例（样本）的个数，M 表示特征数目。<ul><li>1、一次随机选出一个样本，重复 N 次， （有可能出现重复的样本）</li><li>2、随机去选出 m 个特征，m &lt;&lt;M，建立决策树</li></ul></li><li>采取 bootstrap 抽样</li></ul><h4 id="api-4"><a class="anchor" href="#api-4">#</a> API</h4><ul><li><p>class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None, bootstrap=True, random_state=None, min_samples_split=2)</p><ul><li>随机森林分类器</li><li>n_estimators：integer，optional（default = 10）森林里的树木数量 120,200,300,500,800,1200</li><li>criteria：string，可选（default =“gini”）分割特征的测量方法</li><li>max_depth：integer 或 None，可选（默认 = 无）树的最大深度 5,8,15,25,30</li><li>max_features=&quot;auto”, 每个决策树的最大特征数量<ul><li>If &quot;auto&quot;, then <code>max_features=sqrt(n_features)</code> .</li><li>If &quot;sqrt&quot;, then <code>max_features=sqrt(n_features)</code> (same as &quot;auto&quot;).</li><li>If &quot;log2&quot;, then <code>max_features=log2(n_features)</code> .</li><li>If None, then <code>max_features=n_features</code> .</li></ul></li><li>bootstrap：boolean，optional（default = True）是否在构建树时使用放回抽样</li><li>min_samples_split: 节点划分最少样本数</li><li>min_samples_leaf: 叶子节点的最小样本数</li></ul></li><li><p>超参数：n_estimator, max_depth, min_samples_split,min_samples_leaf</p></li></ul><h4 id="代码-3"><a class="anchor" href="#代码-3">#</a> 代码</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 随机森林去进行预测</span></pre></td></tr><tr><td data-num="2"></td><td><pre>rf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>param <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"n_estimators"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">,</span><span class="token number">800</span><span class="token punctuation">,</span><span class="token number">1200</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"max_depth"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 超参数调优</span></pre></td></tr><tr><td data-num="7"></td><td><pre>gc <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>rf<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>gc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"随机森林预测的准确率为："</span><span class="token punctuation">,</span> gc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://cdn.jsdelivr.net/gh/1910853272/image/img/202110011700215.png" alt="机器学习day02"></p><h2 id="回归与聚类算法"><a class="anchor" href="#回归与聚类算法">#</a> 回归与聚类算法</h2><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 机器学习</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-10-01 17:05:32" itemprop="dateModified" datetime="2021-10-01T17:05:32+08:00">2021-10-01</time> </span><span id="2021/08/26/机器学习/机器学习基础/" class="item leancloud_visitors" data-flag-title="机器学习基础" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="lzs 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="lzs 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>lzs <i class="ic i-at"><em>@</em></i>Sakura</li><li class="link"><strong>本文链接：</strong> <a href="https://zengshengli775.gitee.io/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习基础">https://zengshengli775.gitee.io/2021/08/26/机器学习/机器学习基础/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2021/08/25/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/Mac%20VScode%E5%BF%AB%E6%8D%B7%E9%94%AE/" itemprop="url" rel="prev" data-background-image="http:&#x2F;&#x2F;www.dmoe.cc&#x2F;random.php?165624" title="Mac VScode快捷键"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 实用技巧</span><h3>Mac VScode快捷键</h3></a></div><div class="item right"><a href="/2021/08/26/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/" itemprop="url" rel="next" data-background-image="http:&#x2F;&#x2F;www.dmoe.cc&#x2F;random.php?970309" title="数据结构与算法基础"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 数据结构与算法</span><h3>数据结构与算法基础</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">李宏毅机器学习笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%983%E5%A4%A9%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.</span> <span class="toc-text">黑马程序员 3 天快速入门 python 机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E9%A9%AC-3%E5%A4%A9%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-html"><span class="toc-number">3.</span> <span class="toc-text">[黑马] 3 天快速入门 python 机器学习 - html</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0"><span class="toc-number"></span> <span class="toc-text">1. 机器学习概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">1.1 什么是机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">1.2 机器学习算法分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">1.3 开发流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number"></span> <span class="toc-text">2. 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">2.1 数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#211-%E5%8F%AF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text">2.1.1 可用数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#212-sklearn"><span class="toc-number">1.2.</span> <span class="toc-text">2.1.2 sklearn</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">2.2 特征工程介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96"><span class="toc-number">3.</span> <span class="toc-text">2.3 特征抽取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#232-%E5%AD%97%E5%85%B8%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.1.</span> <span class="toc-text">2.3.2 字典特征提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#233-%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text">2.3.3 文本特征提取</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2331sklearnfeature_extractiontextcountvectorizerstop_words%E8%BF%94%E5%9B%9E%E8%AF%8D%E9%A2%91%E7%9F%A9%E9%98%B5%E7%BB%9F%E8%AE%A1%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%89%B9%E5%BE%81%E8%AF%8D%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%AA%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.3.3.1.sklearn.feature_extraction.text.CountVectorizer(stop_words&#x3D;[])	返回词频矩阵，统计每个样本特征词出现的个数。</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#23311%E5%AF%B9%E8%8B%B1%E6%96%87%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">2.3.3.1.1 对英文进行特征提取</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#23312%E5%AF%B9%E4%B8%AD%E6%96%87%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">2.3.3.1.2 对中文进行特征提取</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2332sklearnfeature_extractiontexttfidfvectorizer%E7%94%A8%E4%BB%A5%E8%AF%84%E4%BC%B0%E4%B8%80%E5%AD%97%E8%AF%8D%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E9%9B%86%E6%88%96%E4%B8%80%E4%B8%AA%E8%AF%AD%E6%96%99%E5%BA%93%E4%B8%AD%E7%9A%84%E5%85%B6%E4%B8%AD%E4%B8%80%E4%BB%BD%E6%96%87%E4%BB%B6%E7%9A%84%E9%87%8D%E8%A6%81%E7%A8%8B%E5%BA%A6"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.3.3.2.sklearn.feature_extraction.text.TfidfVectorizer	用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.</span> <span class="toc-text">2.4 特征预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#241%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">2.4.1 归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#242%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">4.2.</span> <span class="toc-text">2.4.2 标准化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="toc-number">5.</span> <span class="toc-text">2.5 特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#251-%E9%99%8D%E7%BB%B4"><span class="toc-number">5.1.</span> <span class="toc-text">2.5.1 降维</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#252%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">5.2.</span> <span class="toc-text">2.5.2 特征选择</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2521%E6%96%B9%E6%B3%95"><span class="toc-number">5.2.1.</span> <span class="toc-text">2.5.2.1 方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2522%E8%BF%87%E6%BB%A4%E5%BC%8F"><span class="toc-number">5.2.2.</span> <span class="toc-text">2.5.2.2 过滤式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#253%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-number">5.3.</span> <span class="toc-text">2.5.3 相关系数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca"><span class="toc-number">6.</span> <span class="toc-text">2.6 主成分分析 (PCA)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">3. 分类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">1.</span> <span class="toc-text">3.1 数据集介绍与划分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">1.1.</span> <span class="toc-text">数据集的划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api"><span class="toc-number">1.2.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.3.</span> <span class="toc-text">sklearn 数据集介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-2"><span class="toc-number">1.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%92%8C%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.5.</span> <span class="toc-text">分类和回归数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.6.</span> <span class="toc-text">返回类型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32sklearn%E8%BD%AC%E6%8D%A2%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8"><span class="toc-number">2.</span> <span class="toc-text">3.2sklearn 转换器和估计器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">2.1.</span> <span class="toc-text">1. 转换器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E4%BC%B0%E8%AE%A1%E5%99%A8sklearn%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.</span> <span class="toc-text">2. 估计器 (sklearn 机器学习算法的实现)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95knn"><span class="toc-number">3.</span> <span class="toc-text">3.3 K - 近邻算法 (KNN)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">距离公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95api"><span class="toc-number">3.3.</span> <span class="toc-text">K - 近邻算法 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE"><span class="toc-number">3.4.</span> <span class="toc-text">预测签到位置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">3.5.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">3.6.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="toc-number">4.</span> <span class="toc-text">3.4 模型选择与调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2grid-search"><span class="toc-number">4.1.</span> <span class="toc-text">超参数搜索 - 网格搜索 (Grid Search)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="toc-number">4.2.</span> <span class="toc-text">模型选择与调优</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#facebook%E7%AD%BE%E5%88%B0%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8Bk%E5%80%BC%E8%B0%83%E4%BC%98"><span class="toc-number">4.3.</span> <span class="toc-text">Facebook 签到位置预测 K 值调优</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#35%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">3.5 朴素贝叶斯算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E4%B8%8E%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87"><span class="toc-number">5.1.</span> <span class="toc-text">条件概率与联合概率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F"><span class="toc-number">5.2.</span> <span class="toc-text">贝叶斯公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91%E7%B3%BB%E6%95%B0"><span class="toc-number">5.3.</span> <span class="toc-text">拉普拉斯平滑系数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-3"><span class="toc-number">5.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20%E7%B1%BB%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB"><span class="toc-number">5.5.</span> <span class="toc-text">20 类新闻分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90-2"><span class="toc-number">5.6.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-2"><span class="toc-number">5.7.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">6.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="toc-number">6.1.</span> <span class="toc-text">信息熵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%85%AC%E5%BC%8F"><span class="toc-number">6.2.</span> <span class="toc-text">信息增益 定义与公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%B8%89%E7%A7%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.3.</span> <span class="toc-text">决策树的三种算法实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91api"><span class="toc-number">6.4.</span> <span class="toc-text">决策树 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B"><span class="toc-number">6.5.</span> <span class="toc-text">泰坦尼克号乘客生存预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">6.6.</span> <span class="toc-text">可视化决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E5%88%B0dot%E6%96%87%E4%BB%B6"><span class="toc-number">6.7.</span> <span class="toc-text">保存树的结构到 dot 文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%BB%E7%BB%93"><span class="toc-number">6.8.</span> <span class="toc-text">决策树总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E4%B9%8B%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">7.</span> <span class="toc-text">集成学习方法之随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">7.1.</span> <span class="toc-text">集成学习方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">7.2.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8E%9F%E7%90%86%E8%BF%87%E7%A8%8B"><span class="toc-number">7.3.</span> <span class="toc-text">随机森林原理过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-4"><span class="toc-number">7.4.</span> <span class="toc-text">API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-3"><span class="toc-number">7.5.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E4%B8%8E%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">回归与聚类算法</span></a></li></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" rel="bookmark" title="机器学习基础">机器学习基础</a></li><li><a href="/2021/09/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%85%AC%E5%BC%8F%202.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="bookmark" title="机器学习算法公式 2.线性回归">机器学习算法公式 2.线性回归</a></li><li><a href="/2021/09/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%85%AC%E5%BC%8F%201.Introduction/" rel="bookmark" title="机器学习算法公式 1.Introduction">机器学习算法公式 1.Introduction</a></li><li><a href="/2021/09/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%85%AC%E5%BC%8F%203.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/" rel="bookmark" title="机器学习算法公式 3.线性分类">机器学习算法公式 3.线性分类</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="lzs" data-src="/images/avatar.jpg"><p class="name" itemprop="name">lzs</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">31</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">12</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">33</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3plbmdzaGVuZ2xpNzc1" title="https:&#x2F;&#x2F;github.com&#x2F;zengshengli775"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9senMtNDg=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;lzs-48"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE4ODAwNzc0NjY=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1880077466"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9naXRlZS5jb20vemVuZ3NoZW5nbGk3NzUvemVuZ3NoZW5nbGk3NzU=" title="https:&#x2F;&#x2F;gitee.com&#x2F;zengshengli775&#x2F;zengshengli775"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2021/08/25/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/Mac%20VScode%E5%BF%AB%E6%8D%B7%E9%94%AE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2021/08/26/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2021/10/01/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/C++%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/" title="C++核心编程">C++核心编程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/" title="分类于 实用技巧">实用技巧</a></div><span><a href="/2021/08/25/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/Mac%20VScode%E5%BF%AB%E6%8D%B7%E9%94%AE/" title="Mac VScode快捷键">Mac VScode快捷键</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%8D%9A%E5%AE%A2/" title="分类于 博客">博客</a></div><span><a href="/2021/08/09/%E5%8D%9A%E5%AE%A2/%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2/" title="搭建Hexo博客">搭建Hexo博客</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%8D%9A%E5%AE%A2/" title="分类于 博客">博客</a></div><span><a href="/2021/08/11/%E5%8D%9A%E5%AE%A2/Hexo%E5%8D%9A%E5%AE%A2%E5%86%99%E6%96%87%E7%AB%A0/" title="Hexo博客写文章">Hexo博客写文章</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%80%83%E7%A0%94/" title="分类于 考研">考研</a></div><span><a href="/2021/08/14/%E8%80%83%E7%A0%94/%E8%80%83%E7%A0%94%E6%B5%81%E7%A8%8B%E8%AE%B0%E5%BD%95/" title="考研流程记录">考研流程记录</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" title="分类于 学习工具">学习工具</a></div><span><a href="/2021/09/22/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/%E4%B8%AD%E6%96%87PDF%E7%94%B5%E5%AD%90%E4%B9%A6%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E4%B9%A6%E7%AD%BE/" title="中文PDF电子书自动添加书签">中文PDF电子书自动添加书签</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" title="分类于 学习工具">学习工具</a></div><span><a href="/2021/08/10/%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/PDF%E4%B9%A6%E7%B1%8D%E4%BB%A3%E6%89%BE/" title="PDF书籍代找">PDF书籍代找</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2021/08/12/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/Python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="Python基础知识">Python基础知识</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%9C%9F%E6%9C%AB/" title="分类于 期末">期末</a></div><span><a href="/2021/08/11/%E6%9C%9F%E6%9C%AB/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E8%B5%84%E6%96%99/" title="期末复习资料">期末复习资料</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" title="分类于 编程基础">编程基础</a></div><span><a href="/2021/08/27/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/C++%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="C++基础知识">C++基础知识</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">lzs @ Sakura</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">222k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">3:22</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2021/08/26/机器学习/机器学习基础/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->